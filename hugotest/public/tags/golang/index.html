<!DOCTYPE html>

<html lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width">
	<title>Dieter&#39;s blog</title>
	<link rel="profile" href="http://gmpg.org/xfn/11">
	<!--[if lt IE 9]>
	<script src="http://localhost:1313//js/html5.js"></script>
	<![endif]-->
    
    <link href="http://localhost:1313//index.xml" rel="alternate" type="application/rss+xml" title="Dieter&#39;s blog" />

    <link rel='stylesheet' id='twentyfourteen-lato-css'  href='//fonts.googleapis.com/css?family=Lato%3A300%2C400%2C700%2C900%2C300italic%2C400italic%2C700italic&#038;subset=latin%2Clatin-ext' type='text/css' media='all' />

    <link rel='stylesheet' id='genericons-css' href='http://localhost:1313//genericons/genericons.css' type='text/css' media='all' />
	<link rel='stylesheet' id='twentyfourteen-style-css' href='http://localhost:1313//css/style.css' type='text/css' media='all' />
	
	<script type='text/javascript' src='http://localhost:1313//js/jquery/jquery.js'></script>
	<script type='text/javascript' src='http://localhost:1313//js/jquery/jquery-migrate.min.js'></script>
	<style type="text/css">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style>
</head>

<body class="home blog masthead-fixed list-view full-width grid">
<div id="page" class="hfeed site">
	<header id="masthead" class="site-header" role="banner">
		<div class="header-main">
			<h1 class="site-title"><a href="http://localhost:1313//index.html" rel="home">Dieter&#39;s blog</a></h1>

			<div class="search-toggle">
				<a href="#search-container" class="screen-reader-text">Search</a>
			</div>

			<nav id="primary-navigation" class="site-navigation primary-navigation" role="navigation">
				<button class="menu-toggle">Primary Menu</button>
				<a class="screen-reader-text skip-link" href="#content">Skip to content</a>
				<div class="nav-menu">
					<ul>
						
						<li class="page_item"> 
							<a href="/">blog</a>
						</li>
						
						<li class="page_item"> 
							<a href="/about/">about</a>
						</li>
						
						<li class="page_item"> 
							<a href="/talks/">talks</a>
						</li>
						
						<li class="page_item"> 
							<a href="https://twitter.com/Dieter_be">tweets</a>
						</li>
						
						<li class="page_item"> 
							<a href="https://github.com/Dieterbe">Github</a>
						</li>
						
					</ul>
				</div>
			</nav>
		</div>

		<div id="search-container" class="search-box-wrapper hide">
			<div class="search-box">
                <script type="text/javascript">
    function site_search(obj) {
    	var host = window.location.host;
        obj.q.value = "site:" + host + " " + obj.ss_q.value;
    }
</script>

<aside id="search-3" class="widget widget_search">
	<form role="search" class="search-form" action="//www.google.com/search" method="get" onSubmit="site_search(this)">

	<input name="q" type="hidden" />
	    <label>
	        <span class="screen-reader-text">Search for:</span>
	        <input name="ss_q" type="text" placeholder="Search ..." class="search-field" />
	    </label>
	    <input type="submit" value="Search" class="search-submit" />
	</form>
</aside>
			</div>
		</div>
	</header>

	<div id="main" class="site-main">


<div id="main-content" class="main-content">

	<div id="primary" class="content-area">
		<div id="content" class="site-content" role="main">

			<header class="archive-header">
				<h1 class="archive-title">Content tagged "Golang"</h1>
			</header>

			
				<article class="post type-post status-publish format-standard hentry">

	
	<header class="entry-header">

	

		<div class="entry-meta">
			<span class="cat-links">
                
			</span>
		</div>

        <h1 class="entry-title"><a href="http://localhost:1313/post/a-real-whisper-to-influxdb-program/">A real whisper-to-InfluxDB program.</a></h1>

		<div class="entry-meta">
			<span class="entry-date">
				<a href="http://localhost:1313/post/a-real-whisper-to-influxdb-program/" rel="bookmark">
					<time class="entry-date" datetime="2014-09-30 08:37:48 -0400 EDT">
						September 30, 2014
					</time>
				</a>
			</span>
		</div>

	</header>
	
	<div class="entry-content">
		The <a href="/graphite-influxdb-intermezzo-migrating-old-data-and-a-more-powerful-carbon-relay.html">whisper-to-influxdb migration script</a> I posted earlier is pretty bad.  A shell script, without concurrency, and an undiagnosed performance issue.

I hinted that one could write a Go program using the unofficial <a href="https://github.com/kisielk/whisper-go">whisper-go</a> bindings and the <a href="https://github.com/influxdb/influxdb/tree/master/client">influxdb Go client library</a>.

That's what I did now, it's at <a href="https://github.com/vimeo/whisper-to-influxdb">github.com/vimeo/whisper-to-influxdb</a>.

It uses configurable amounts of workers for both whisper fetches and InfluxDB commits,

but it's still a bit naive in the sense that it commits to InfluxDB one serie at a time, irrespective of how many records are in it.

My series, and hence my commits have at most 60k records, and presumably InfluxDB could handle a lot more per commit, so we might leverage better batching later.  Either way, this way I can consistently commit about 100k series every 2.5 hours (or 10/s), where each serie has a few thousand points on average, with peaks up to 60k points. I usually play with 1 to 30 InfluxDB workers. 

Even though I've hit a few <a href="https://github.com/influxdb/influxdb/issues/985">InfluxDB</a> <a href="https://github.com/influxdb/influxdb/issues/970">issues</a>, this tool has enabled me to fill in gaps after outages and to do a restore from whisper after a complete database wipe.



	</div>

	<footer class="entry-meta">
		<span class="tag-links">		
			
                <a href="http://localhost:1313//tags/devops/index.html" rel="tag">devops</a>
            
                <a href="http://localhost:1313//tags/monitoring/index.html" rel="tag">monitoring</a>
            
                <a href="http://localhost:1313//tags/golang/index.html" rel="tag">golang</a>
            
		</span>
	</footer>
</article> 

			
				<article class="post type-post status-publish format-standard hentry">

	
	<header class="entry-header">

	

		<div class="entry-meta">
			<span class="cat-links">
                
			</span>
		</div>

        <h1 class="entry-title"><a href="http://localhost:1313/post/influxdb-as-graphite-backend-part2/">InfluxDB as a graphite backend, part 2</a></h1>

		<div class="entry-meta">
			<span class="entry-date">
				<a href="http://localhost:1313/post/influxdb-as-graphite-backend-part2/" rel="bookmark">
					<time class="entry-date" datetime="2014-09-24 07:56:01 -0400 EDT">
						September 24, 2014
					</time>
				</a>
			</span>
		</div>

	</header>
	
	<div class="entry-content">
		<br>

<br/>Updated oct 1, 2014 with a new <i>Disk space efficiency</i> section which fixes some mistakes and adds more clarity.

<br/>



<p>

The <i>Graphite + InfluxDB</i> series continues.

<ul>

<li>In part 1, <a href="/on-graphite-whisper-and-influxdb.html">"On Graphite, Whisper and InfluxDB"</a> I described the problems of Graphite's whisper and ceres, why I disagree with common graphite clustering advice as being the right path forward, what a great timeseries storage system would mean to me, why InfluxDB - despite being the youngest project - is my main interest right now, and introduced my approach for combining both and leveraging their respective strengths: InfluxDB as an ingestion and storage backend (and at some point, realtime processing and pub-sub) and graphite for its renown data processing-on-retrieval functionality.

Furthermore, I introduced some tooling: <a href="https://github.com/graphite-ng/carbon-relay-ng">carbon-relay-ng</a> to easily route streams of carbon data (metrics datapoints) to storage backends, allowing me to send production data to Carbon+whisper as well as InfluxDB in parallel, <a href="https://github.com/brutasse/graphite-api">graphite-api</a>, the simpler Graphite API server, with <a href="https://github.com/vimeo/graphite-influxdb">graphite-influxdb</a> to fetch data from InfluxDB.

</li>

<li>Not Graphite related, but I wrote <a href="https://github.com/Dieterbe/influx-cli">influx-cli</a> which I introduced <a href="/influx-cli_a_commandline_interface_to_influxdb.html">here</a>.  It allows to easily interface with InfluxDB and measure the duration of operations, which will become useful for this article.</li>

<li>In the <a href="graphite-influxdb-intermezzo-migrating-old-data-and-a-more-powerful-carbon-relay.html">Graphite &amp; Influxdb intermezzo</a> I shared a script to import whisper data into InfluxDB and noted some write performance issues I was seeing, but the better part of the article described the various improvements done to <a href="https://github.com/graphite-ng/carbon-relay-ng">carbon-relay-ng</a>, which is becoming an increasingly versatile and useful tool.</li>

<li>In <a href="/using-influxdb-as-graphite-backend-part2.html">part 2</a>, which you are reading now, I'm going to describe recent progress, share more info about my setup, testing results, state of affairs, and ideas for future work</li>

</ul>

<!--more-->



<h4>Progress made</h4>

<ul>

<li>InfluxDB saw two major releases:

<ul>

<li>0.7 (and followups), which was mostly about some needed features and bug fixes</li>

<li>0.8 was all about bringing some major refactorings in the hands of early adopters/testers: support for multiple storage engines, configurable shard spaces, rollups and retention schemes. There was some other useful stuff like speed and robustness improvements for the graphite input plugin (by yours truly) and various things like regex filtering for 'list series'.  Note that a bunch of older bugs remained open throughout this release (most notably the broken <a href="https://github.com/influxdb/influxdb/issues/334">derivative aggregator</a>), and a bunch of new ones appeared. Maybe this is why the release was mostly in the dark.  In this context, it's not so bad, because we let graphite-api do all the processing, but if you want to query InfluxDB directly you might hit some roadblocks.</li>

<li>An older fix, but worth mentioning: series names can now also contain any character, which means you can easily use <a href="http://metrics20.org/">metrics2.0</a> identifiers.  This is a welcome relief after having struggled with Graphite's restrictions on metric keys.</li>

</ul>

</li>

<li><a href="http://graphite-api.readthedocs.org">graphite-api</a> received various bug fixes and support for templating, statsd instrumentation and caching.

<br/>Much of this was driven by graphite-influxdb: the caching allows us to cache metadata and the statsd integration gives us insights into the performance of the steps it goes through of building a graph (getting metadata from InfluxDB, querying InfluxDB, interacting with cache, post processing data, etc).</li>

<li>the progress on InfluxDB and graphite-api in turn enabled <a href="https://github.com/vimeo/graphite-influxdb">graphite-influxdb</a> to become faster and simpler (note: graphite-influxdb requires InfluxDB 0.8).  Furthermore you can now configure series resolutions (but different retentions per serie is on the roadmap, see <i>State of affairs and what's coming</i>), and of course it also got a bunch of bugfixes.</li>

</ul>

Because of all these improvements, all involved components are now ready for serious use.



<h4>Putting it all together, with docker</h4>

<a href="https://www.docker.com/">Docker</a> probably needs no introduction, it's a nifty tool to build an environment with given software installed, and allows to easily deploy it and run it in isolation.

<a href="https://github.com/vimeo/graphite-api-influxdb-docker">graphite-api-influxdb-docker</a> is a very creatively named project that generates the - also very creatively named - docker image <a href="https://registry.hub.docker.com/u/vimeo/graphite-api-influxdb/">graphite-api-influxdb</a>, which contains graphite-api and graphite-influxdb, making it easy to hook in a customized configuration and get it up and running quickly.  This is the recommended way to set this up, and this is what we run in production.



<h4>The setup</h4>

<ul>

<li>a server running InfluxDB and graphite-api with graphite-influxdb via the docker approach described above:

<pre>

dell PowerEdge R610

24 x Intel(R) Xeon(R) X5660  @ 2.80GHz

96GB RAM

perc raid h700

6x600GB seagate 10k rpm drives in raid10 = 1.6 TB, Adaptive Read Ahead, Write Back, 64 kB blocks, no read caching

no sharding/shard spaces, compiled from git just before 0.8, using LevelDB (not rocksdb, which is now the default)

LevelDB max-open-files = 10000 (lsof shows about 30k open files total for the InfluxDB process), LRU 4096m, everything else is default I think.

</pre>

</li>

<li>a server running graphite-web, carbon, and whisper:

<pre>

dell PowerEdge R710

16 x Intel(R) Xeon(R) E5640  @ 2.67GHz

96GB RAM

perc raid h700

8x150GB seagate 15k rm in raid5 = 952 GB, Read Ahead, Write Back, 64 kB blocks, no read caching

MAX_UPDATES_PER_SECOND = 1000  # to sequentialize writes

</pre>

</li>

<li>a relay server running carbon-relay-ng that sends the same production load into both.  (about 2500 metrics/s, or 150k minutely)</li>

</ul>

As you can tell, on both machines RAM is vastly over provisioned, and they have lots of cpu available (the difference in cores should be negligible), but the difference in RAID level is important to note: RAID 5 comes with a write penalty. Even though the whisper machine has more, and faster disks, it probably has a disadvantage for writes.  Maybe.  Haven't done raid stuff in a long time, and I haven't it measured it out.

<br/><b>Clearly you'll need to take the results with a grain of salt, as unfortunately I do not have 2 systems available with the same configuration and their baseline (raw) performance is unknown.</b>.

<br/>Note: no InfluxDB clustering, see <i>State of affairs and what's coming</i>.



<h4>The empirical validation &amp; migration</h4>

Once everything was setup and I could confidently send 100% of traffic to InfluxDB via carbon-relay-ng, it was trivial to run our dashboards with a flag deciding which server to go to.

This way I have literally been running our graphite dashboards next to each other, allowing us to compare both stacks on:

<ul>

<li>visual differences: after a bunch of work and bug fixing, we got to a point where both dashboards looked almost exactly the same.  (note that graphite-api's implementation of certain functions can behave slightly different, see for example this <a href="https://github.com/brutasse/graphite-api/issues/66">divideSeries bug</a>)</li>

<li>speed differences by simply refreshing both pages and watching the PNGs load, with some assistance from firebug's network requests profiler.  The difference here was big: graphs served up by graphite-api + InfluxDB loaded considerably faster.  A page with 40 graphs or so would load in a few seconds instead of 20-30 seconds (on both first, as well as subsequent hits).  This is for our default, 6-hour timeframe views.  When cranking the timeframes up to a couple of weeks, graphite-api + InfluxDB was still faster.</li>

</ul>

Soon enough my colleagues started asking to make graphite-api + InfluxDB the default, as it was much faster in all common cases.  I flipped the switch and everybody has been happy.

<br/>

<br/>

When loading a page with many dashboards, the InfluxDB machine will occasionally spike up to 500% cpu, though I rarely get to see any iowait (!), even after syncing the block cache (i just realized it'll probably still use the cache for reads after sync?)

<br/>The carbon/whisper machine, on the other hand, is always fighting iowait, which could be caused by the raid 5 write amplification but the random io due to the whisper format probably has more to do with it.  Via the MAX_UPDATES_PER_SECOND I've tried to linearize writes, with mixed success.  But I've never gone to deep into it.  So basically <b>comparing write performance would be unfair in these circumstances, I am only comparing reads in these tests</b>.  Despite the different storage setups, the Linux block cache should make things fair for reads.   Whisper's iowait will handicap the reads, but I always did successive runs with fully loaded PNGs to make sure the block cache was warm for reads.



<h4>A "slightly more professional" benchmark</h4>

I could have stopped here, but the validation above was not very scientific.  I wanted to do a somewhat more formal benchmark, to measure read speeds (though I did not have much time so it had to be quick and easy).

<br/>I wanted to compare InfluxDB vs whisper, and specifically how performance scales as you play with parameters such as number of series, points per series, and time range fetched (i.e. amount of points).  I <a href="https://groups.google.com/forum/#!topic/influxdb/0VeUQCqzgVg">posted the benchmark on the InfluxDB mailing list</a>.  Look there for all information. I just want to reiterate the conclusion here:  I was surprised.  Because of the results above, I had assumed that InfluxDB would perform reads noticeably quicker than whisper but this is not the case.  (maybe because whisper reads are nicely sequential - it's mostly writes that suffer from the whisper format)

<br/>This very much contrasts my earlier findings where the graphite-api+InfluxDB powered dashboards clearly take the lead.  I have yet to figure out why this is.  Maybe something to do with the performance of graphite-web vs graphite-api itself, gunicorn vs apache, worker configuration, or maybe InfluxDB only starts outperforming whisper as concurrency increases.  Some more investigation is definitely needed!



<h4>Future benchmarks</h4>

The simple benchmark above was very simple to execute, as it only requires influx-cli and whisper-fetch (so you can easily check for yourself), but clearly there is a need to test more realistic scenarios with concurrent reads, and doing some write benchmarks would be nice too.

<br/>We should also look into cpu and memory usage.  I have had the luxury of being able to completely ignore memory usage, but others seem to notice excessive InfluxDB memory usage.

<br/>conclusion: many tests and benchmarks should happen, but I don't really have time to conduct them.  Hopefully other people in the community will take this on.



<h4>Disk space efficiency</h4>

Last time I checked, using LevelDB I was pretty close to 24B per record (which makes sense because time, seq_no and value are all 64bit values, and each record has those 3 fields).  (this was with snappy compression enabled, so it didn't seem to give much benefit).

<br/>Whisper seems to consume 12 Bytes per record - a 32bit timestamp and a 64bit float value - making it considerably more storage efficient than InfluxDB/levelDB for now.

<br/>Some notes on this though:

<ul>

<li>whisper explicitly encodes None values, with InfluxDB those are implied (and require no space).  We have some clusters of metrics that have very sparse data, so whisper gives us a lot of overhead here, but this is different for everyone.  (note: Ceres should also be better at handling sparse data)</li>

<li>Whisper and Influxdb both explictly encode the timestamp for every record.  Influxdb uses 64bit so you can do very high resolution (up to microseconds), whisper is limited to per-second data.  Ceres AFAIK doesn't explicitly encode the timestamp at every record, which should also give it a space advantage.</li>

<li>I've been using a data format in InfluxDB where every record is timestamp-sequence_number-value.  It currently works best overall, and so that's how the graphite ingestion plugin stores it and the graphite-influxdb plugin queries for it.  But it exacerbates the overhead of the timestamp and sequence number.

<br/>We could technically use a row format where we use more variables as part of the record, storing them as columns instead of separate series, which would improve this dynamic (but currently comes with a big tradeoff in performance characteristics - see the <a href="https://github.com/influxdb/influxdb/issues/582">column indexes</a> ticket).

<br/>Another thing is that we could technically come up with a storage format for InfluxDB that is optimized for even-spaced metrics, it wouldn't need sequence numbers, and timestamps could be implicit instead of explicit, saving a lot of space.  We could even go further and introduce types (int, etc) for values which would consume even less space.

</ul>

<br/>

It would be great if somebody with more Ceres experience could chip in here, as - in the context of space efficiency - it looks like a neat little format.

Also, I'm probably not making proper use of the compression features that InfluxDB's storage engines support.  This also requires some more looking into.





<h4>State of affairs and what's coming</h4>

<ul>

<li>InfluxDB typically performs pretty well, but not in all cases.  More validation is needed. It wouldn't surprise me at this point if tools like hbase/Cassandra/riak clearly outperform InfluxDB, as long as we keep in mind that InfluxDB is a young project.  A year, or two, from now, it'll probably perform much better. (and then again, it's not all about raw performance.  InfluxDB's has other strengths)</li>

<li>A long time goal which is now a reality:  <b>You can use any Graphite dashboard on top of InfluxDB, as long as the data is stored in a graphite-compatible format.</b>.  Again, the easiest to get running is via <a href="https://github.com/vimeo/graphite-api-influxdb-docker">graphite-api-influxdb-docker</a>.  There are two issues to be mentioned, though:

<ul>

<li>graphite-influxdb needs to query InfluxDB for metadata, and this <a href="https://github.com/influxdb/influxdb/issues/884">can be slow</a>.  If you have millions of metrics, it can take tens of seconds before querying for the data even starts.  I am trying to work with the InfluxDB people on a solution.</li>

<li><a href="https://github.com/brutasse/graphite-api/issues/57">graphite-api doesn't work with metric id's that have equals signs in them</a>.</li>

</ul>

<li>With the 0.8 release out the door, the shard spaces/rollups/retention intervals feature will start stabilizing, so we can start supporting multiple retention intervals per metric</li>

<li>Because InfluxDB clustering is <a href="https://github.com/influxdb/influxdb/pull/903">undergoing major changes</a>, and because clustering is not a high priority for me, I haven't needed to worry about this.  I'll probably only start looking at clustering somewhere in 2015 because I have more pressing issues.</li>

<li>Once the new clustering system and the storage subsystem have matured (sounds like a v1.0 ~ v1.2 to me) we'll get more speed improvements and robustness.  Most of the integration work is done, it's just a matter of doing smaller improvements, bug fixes and waiting for InfluxDB to become better.  Maintaining this stack aside, I personally will start focusing more on:

    <ul>

    <li>per-second resolution in our data feeds, and potentially storage</li>

    <li>realtime (but basic) anomaly detection, realtime graphs for some key timeseries.  Adrian Cockcroft had an inspirational piece in his <a href="https://vimeo.com/95064249">Monitorama keynote</a> about how alerts from timeseries should trigger within seconds.</li>

    <li>Mozilla's awesome <a href="http://hekad.readthedocs.org">heka</a> project (this <a href="https://vimeo.com/98689689">heka video</a> is great), which should help a lot with the above.  Also looking at <a href="http://codeascraft.com/2013/06/11/introducing-kale/">Etsy's kale stack</a> for anomaly detection</li>

    <li>metrics 2.0 and making sure metrics 2.0 works well with InfluxDB.  Up to now I find the series / columns as a data model too limiting and arbitrary, it could be so much more powerful, ditto for the query language.</li>

</ul>

</li>

<li>Can we do anything else to make InfluxDB (+graphite) faster? Yes!

<ul>

<li>Long term, of course, InfluxDB should have powerful enough processing functions and query syntax, so that we don't even need a graphite layer anymore.</li>

<li>A storage engine optimized for fixed intervals would probably help, timestamps and sequence numbers currently consume 2/3 of the record... and there's no reason to explicitly store either one in this use case.  I've even rarely seen people make use of the sequence number in any other InfluxDB use case.  See all the remarks in the <i>Disk space efficiency</i> section above.  Finally we could have InfluxDB have fill in None values without it doing "group by" (timeframe consolidation), which would shave off runtime overhead.</li>

<li>Then of course, there are projects to replace graphite-web/graphite-api with a Go codebase: <a href="https://github.com/graphite-ng/graphite-ng">graphite-ng</a> and <a href="https://github.com/dgryski/carbonapi">carbonapi</a>.  the latter is more production ready, but depends on some custom tooling and io using protobufs.  But it performs an order of magnitude better than the python api server!  I haven't touched graphite-ng in a while, but hopefully at some point I can take it up again</li>

</ul>

<li>Another thing to keep in mind when switching to graphite-api + InfluxDB: you loose the graphite composer.  I have a few people relying on this, so I can either patch it to talk to graphite-api (meh), separate it out (meh) or replace it with a nicer dashboard like tessera, grafana or descartes.  (or Graph-Explorer, but it can be a bit too much of a paradigm shift).</li>

<li>some more InfluxDB stuff I'm looking forward to:

<ul>

<li>binary protocol and result streaming (faster communication and responses!) (the latter might not get implemented though)</li>

<li>"list series" speed improvements (if metadata querying gets fast enough, we won't need ES anymore for metrics2.0 index)</li>

<li><a href="https://github.com/influxdb/influxdb/pull/635">InfluxDB instrumentation</a> so we actually start getting an idea of what's going on in the system, a lot of the testing and troubleshooting is still in the dark.</li>

</ul>

</li>

<li>Tracking exceptions in graphite-api is <a href="https://github.com/brutasse/graphite-api/search?q=exception&type=Issues&utf8=%E2%9C%93">much harder than it should be</a>.  Currently there's no way to display exceptions to the user (in the http response) or to even log them.  So sometimes you'll get http 500 responses and don't know why.  You can use the <a href="http://graphite-api.readthedocs.org/en/latest/configuration.html#extra-sections">sentry integration</a> which works all right, but is clunky.  Hopefully this will be addressed soon.</li>

</ul>



<h4>Conclusion</h4>

The graphite-influxdb stack works and is ready for general consumption.  It's easy to install and operate, and performs well.

It is expected that InfluxDB will over time mature and ultimately meet all my <a href="/on-graphite-whisper-and-influxdb.html">requirements of the ideal backend</a>.  It definitely has a long way to go.  More benchmarks and tests are needed.  Keep in mind that we're not doing large volumes of metrics. For small/medium shops this solution should work well, but on larger scales you will definitely run into issues.  You might conclude that InfluxDB is not for you (yet) (there are alternative projects, after all).

<br/>

<br/>

Finally, a closing thought:

<br/><i>Having graphs and dashboards that look nice and load fast is a good thing to have, but keep in mind that graphs and dashboards should be a last resort.  It's a solution if all else fails.  The fewer graphs you need, the better you're doing.

<br/>How can you avoid needing graphs?  Automatic alerting on your data.

<br/>

<br/>I see graphs as a temporary measure: they provide headroom while you develop an understanding of the operational behavior of your infrastructure, conceive a model of it, and implement the alerting you need to do troubleshooting and capacity planning.  Of course, this process consumes more resources (time and otherwise), and these expenses are not always justifiable, but I think this is the ideal case we should be working towards.</i>



<br/>

<br/>

Either way, good luck and have fun!

	</div>

	<footer class="entry-meta">
		<span class="tag-links">		
			
                <a href="http://localhost:1313//tags/devops/index.html" rel="tag">devops</a>
            
                <a href="http://localhost:1313//tags/monitoring/index.html" rel="tag">monitoring</a>
            
                <a href="http://localhost:1313//tags/golang/index.html" rel="tag">golang</a>
            
		</span>
	</footer>
</article> 

			
				<article class="post type-post status-publish format-standard hentry">

	
	<header class="entry-header">

	

		<div class="entry-meta">
			<span class="cat-links">
                
			</span>
		</div>

        <h1 class="entry-title"><a href="http://localhost:1313/post/graphite-influxdb-intermezzo-migrating-old-data-and-a-more-powerful-carbon-relay/">Graphite &amp; Influxdb intermezzo: migrating old data and a more powerful carbon relay</a></h1>

		<div class="entry-meta">
			<span class="entry-date">
				<a href="http://localhost:1313/post/graphite-influxdb-intermezzo-migrating-old-data-and-a-more-powerful-carbon-relay/" rel="bookmark">
					<time class="entry-date" datetime="2014-09-20 15:18:32 -0400 EDT">
						September 20, 2014
					</time>
				</a>
			</span>
		</div>

	</header>
	
	<div class="entry-content">
		<!--more-->



<h4>Migrating data from whisper into InfluxDB</h4>



<i>"How do i migrate whisper data to influxdb"</i> is a question that comes up regularly, and I've always replied it should be easy to write a tool

to do this.  I personally had no need for this, until a recent small influxdb outage where I wanted to sync data from our backup server (running graphite + whisper) to influxdb, so I wrote a script:



<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%">&lt;!<span style="color: #666666">[</span>CDATA<span style="color: #666666">[</span>

<span style="color: #408080; font-style: italic">#!/bin/bash</span>

<span style="color: #408080; font-style: italic"># whisper dir without trailing slash.</span>

<span style="color: #19177C">wsp_dir</span><span style="color: #666666">=</span>/opt/graphite/storage/whisper

<span style="color: #19177C">start</span><span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">$(</span>date -d <span style="color: #BA2121">&#39;sep 17 6am&#39;</span> +%s<span style="color: #008000; font-weight: bold">)</span>

<span style="color: #19177C">end</span><span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">$(</span>date -d <span style="color: #BA2121">&#39;sep 17 12pm&#39;</span> +%s<span style="color: #008000; font-weight: bold">)</span>

<span style="color: #19177C">db</span><span style="color: #666666">=</span>graphite

<span style="color: #19177C">pipe_path</span><span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">$(</span>mktemp -u<span style="color: #008000; font-weight: bold">)</span>

mkfifo <span style="color: #19177C">$pipe_path</span>

<span style="color: #008000; font-weight: bold">function</span> influx_updater<span style="color: #666666">()</span> <span style="color: #666666">{</span>

    influx-cli -db <span style="color: #19177C">$db</span> -async &lt; <span style="color: #19177C">$pipe_path</span>

<span style="color: #666666">}</span>

influx_updater &amp;

<span style="color: #008000; font-weight: bold">while</span> <span style="color: #008000">read </span>wsp; <span style="color: #008000; font-weight: bold">do</span>

  <span style="color: #19177C">series</span><span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">$(</span>basename <span style="color: #BB6688; font-weight: bold">${</span><span style="color: #19177C">wsp</span>//<span style="color: #BB6622; font-weight: bold">\/</span>/.<span style="color: #BB6688; font-weight: bold">}</span> .wsp<span style="color: #008000; font-weight: bold">)</span>

  <span style="color: #008000">echo</span> <span style="color: #BA2121">&quot;updating </span><span style="color: #19177C">$series</span><span style="color: #BA2121"> ...&quot;</span>

  whisper-fetch.py --from<span style="color: #666666">=</span><span style="color: #19177C">$start</span> --until<span style="color: #666666">=</span><span style="color: #19177C">$end</span> <span style="color: #19177C">$wsp_dir</span>/<span style="color: #19177C">$wsp</span>.wsp | grep -v <span style="color: #BA2121">&#39;None$&#39;</span> | awk <span style="color: #BA2121">&#39;{print &quot;insert into \&quot;&#39;</span><span style="color: #19177C">$series</span><span style="color: #BA2121">&#39;\&quot; values (&quot;$1&quot;000,1,&quot;$2&quot;)&quot;}&#39;</span> &gt; <span style="color: #19177C">$pipe_path</span>

<span style="color: #008000; font-weight: bold">done</span> &lt; &lt;<span style="color: #666666">(</span>find <span style="color: #19177C">$wsp_dir</span> -name <span style="color: #BA2121">&#39;*.wsp&#39;</span> | sed -e <span style="color: #BA2121">&quot;s#</span><span style="color: #19177C">$wsp_dir</span><span style="color: #BA2121">/##&quot;</span> -e <span style="color: #BA2121">&quot;s/.wsp</span><span style="color: #19177C">$/</span><span style="color: #BA2121">/&quot;</span><span style="color: #666666">)</span>

<span style="color: #666666">]]</span>&gt;
</pre></div>
<p>





It relies on the recently introduced asynchronous inserts feature of <a href="https://github.com/Dieterbe/influx-cli">influx-cli</a> - which commits inserts in batches to improve the speed - and the whisper-fetch tool.

<br/>

You could probably also write a Go program using the unofficial <a href="https://github.com/kisielk/whisper-go">whisper-go</a> bindings and the <a href="https://github.com/influxdb/influxdb/tree/master/client">influxdb Go client library</a>.  But I wanted to keep it simple.  Especially when I found out that whisper-fetch is not a bottleneck: starting whisper-fetch, and reading out - in my case - 360 datapoints of a file always takes about 50ms, whereas InfluxDB at first only needed a few ms to flush hundreds of records, but that soon increased to seconds.

<br/>Maybe it's a bug in my code, I didn't test this much, because I didn't need to; but people keep asking for a tool so here you go.  Try it out and maybe you can fix a bug somewhere.  Something about the write performance here must be wrong.



<h4>A more powerful carbon-relay-ng</h4>

<a href="https://github.com/graphite-ng/carbon-relay-ng">carbon-relay-ng</a> received a bunch of love and has been a great help in my graphite+influxdb experiments.

<p>

<a href="/files/carbon-relay-web-ui.png"><img width="441" src="/files/carbon-relay-web-ui.png" /></a>

</p>

Here's what changed:

<ul>

<li>First I made it so that you can adjust routes at runtime while data is flowing through, via a telnet interface.</li>

<li>Then <a href="https://github.com/pauloconnor">Paul O'Connor</a> built an embedded web interface to manage your routes in an easier and prettier way (pictured above)</li>

<li>The relay now also emits performance metrics via statsd (I want to make this better by using <a href="https://github.com/rcrowley/go-metrics">go-metrics</a> which will hopefully get <a href="https://github.com/rcrowley/go-metrics/issues/68">expvar support</a> at some point - any takers?).</li>

<li>Last but not least, I borrowed <a href="https://github.com/graphite-ng/carbon-relay-ng/tree/master/nsqd">the diskqueue</a> code from <a href="http://nsq.io/">NSQ</a> so now we can also spool to disk to bridge downtime of endpoints and re-fill them when they come back up</li>

</ul>

Beside our metrics storage, I also plan to put our anomaly detection (currently playing with <a href="http://hekad.readthedocs.org/en/v0.7.1/">heka</a> and <a href="http://codeascraft.com/2013/06/11/introducing-kale/">kale</a>) and <a href="https://github.com/vimeo/carbon-tagger">carbon-tagger</a> behind the relay, centralizing all routing logic, making things more robust, and simplifying our system design.  The spooling should also help to deploy to our metrics gateways at other datacenters, to bridge outages of datacenter interconnects.

<br/>

<br/>

I used to think of carbon-relay-ng as the python carbon-relay but on steroids,

now it reminds me more of something like nsqd but with an ability to make packet routing decisions by introspecting the carbon protocol,

<br/>or perhaps Kafka but much simpler, single-node (no HA), and optimized for the domain of carbon streams.

<br/>I'd like the HA stuff though, which is why I spend some of my spare time figuring out the intricacies of the increasingly popular <a href="http://raftconsensus.github.io/">raft</a> consensus algorithm.   It seems opportune to have a simpler Kafka-like thing, in Go, using raft, for carbon streams.

(note: InfluxDB <a href="https://github.com/influxdb/influxdb/pull/859">might introduce such a component</a>, so I'm also a bit waiting to see what they come up with)

<br/>

<br/>

Reminder: notably missing from carbon-relay-ng is round robin and sharding.  I believe sharding/round robin/etc should be part of a broader HA design of the storage system, as I explained in <a href="http://dieter.plaetinck.be/on-graphite-whisper-and-influxdb.html">On Graphite, Whisper and InfluxDB</a>.  That said, both should be fairly easy to implement in carbon-relay-ng, and I'm willing to assist those who want to contribute it.

	</div>

	<footer class="entry-meta">
		<span class="tag-links">		
			
                <a href="http://localhost:1313//tags/devops/index.html" rel="tag">devops</a>
            
                <a href="http://localhost:1313//tags/monitoring/index.html" rel="tag">monitoring</a>
            
                <a href="http://localhost:1313//tags/golang/index.html" rel="tag">golang</a>
            
		</span>
	</footer>
</article> 

			
				<article class="post type-post status-publish format-standard hentry">

	
	<header class="entry-header">

	

		<div class="entry-meta">
			<span class="cat-links">
                
			</span>
		</div>

        <h1 class="entry-title"><a href="http://localhost:1313/post/influx-cli_a_commandline_interface_to_influxdb/">Influx-cli: a commandline interface to Influxdb.</a></h1>

		<div class="entry-meta">
			<span class="entry-date">
				<a href="http://localhost:1313/post/influx-cli_a_commandline_interface_to_influxdb/" rel="bookmark">
					<time class="entry-date" datetime="2014-09-08 08:36:36 -0400 EDT">
						September 8, 2014
					</time>
				</a>
			</span>
		</div>

	</header>
	
	<div class="entry-content">
		<p>

Time for another side project:

<a href="https://github.com/Dieterbe/influx-cli">influx-cli</a>,

a commandline interface to influxdb.

<br/>

Nothing groundbreaking, and it behaves pretty much as you would expect if you've ever used

the mysql, pgsql, vsql, etc tools before.

<br/>But I did want to highlight a few interesting features.

</p>

<!--more-->

<br/>



<p>

<b>You can do things like user management via SQL,

even though influxdb doesn't have an SQL interface for this.</b>

<br/>This is much easier than doing curl http requests!

<pre><![CDATA[

influx> create admin test test

influx> list admin

## 0

                     name root

## 1

                     name test

]]></pre>

</p>



<p>

<b>You can change parameters and re-bind with the new values</b>

<pre><![CDATA[

influx> \user test

influx> \pass test

influx> \db graphite

influx> bind

]]></pre>

</p>



<p>

<b>Write your variables (user, pass, host, db, ...) to ~/.influxrc</b>

<pre><![CDATA[

influx> writerc

]]></pre>

</p>



<p>

<b>You can even do inserts via SQL, instead of http posts</b>

<br>I use this often.  This is very useful to script test cases for bug reports etc.

<pre><![CDATA[

influx> create db issue-1234

influx> \db issue-1234

influx> bind

influx> insert into demo (time, value, tag) values (120000, 10, "hi")

influx> insert into demo (time, value, tag) values (180000, 20, "hi again")

influx> select * from demo

## demo

                time sequence_number               value                 tag

       120000.000000      70001.000000                  10                "hi"

       180000.000000      80001.000000                  20          "hi again"

influx> delete db issue-1234

]]></pre>

</p>



<p>

<b>You can send queries on standard input, which is useful in shell commands and scripts.</b>

<pre><![CDATA[

$ echo 'list series' | influx-cli | wc -l

194722

$ influx-cli <<< 'list series' | wc -l

194722

]]></pre>

</p>



<p>

But even better, <b>from inside an influx-cli session, you can send output from any query into any other command.</b>

<br>In fact you can also <b>write output of queries into external files.</b>

All this via familiar shell constructs

<pre><![CDATA[

$ influx-cli

influx> list series | wc -l

194721

influx> list series > list-series.txt

]]></pre>



(note: the discrepancy of one line is due to <a href="https://github.com/shavac/readline/issues/2">the Go readline library echoing the query</a>.

</p>



<p>

<b>You can also toggle options, such as compression or display of timings.</b>

<br/>This can be very useful to easily get insights of performance of different operations.

<pre><![CDATA[

influx> \t

timing is now true

influx> select * from foo | wc -l

64637

timing>

query+network: 1.288792048s

displaying   : 457.091811ms

influx> \comp

compression is now disabled

influx> select * from foo | wc -l

64637

timing>

query+network: 969.322374ms

displaying   : 670.736018ms

influx> list series >/dev/null

timing>

query+network: 3.109178142s

displaying   : 65.712027ms

]]></pre>

<br/>This has enabled me to pinpoint slow operations and provide evidence when <a href="https://github.com/influxdb/influxdb/issues/884">when creating tickets</a>.

</p>



<p>

<b>Executing queries and debugging their result data format, works too</b>

<br/>This is useful when you want to understand the api better or if the database gets support for new queries with a different output format that influx-cli doesn't understand yet.

<pre><![CDATA[

influx> raw select * from foo limit 1

([]*client.Series) (len=1 cap=4) {

 (*client.Series)(0xc20b4f0480)({

  Name: (string) (len=51) "foo",

  Columns: ([]string) (len=3 cap=4) {

   (string) (len=4) "time",

   (string) (len=15) "sequence_number",

   (string) (len=5) "value"

  },

  Points: ([][]interface {}) (len=1 cap=4) {

   ([]interface {}) (len=3 cap=4) {

    (float64) 1.410148588e+12,

    (float64) 1,

    (float64) 95.549995

   }

  }

 })

}

]]></pre>

</p>



<p>

And that's about it.

I've found this to be a much easier way to interface with InfluxDB then using the web interface and curl, but YMMV.

<br/>If you were wondering, this is of course built on top of the <a href="https://github.com/influxdb/influxdb/tree/master/client">influxdb go client library</a>, which was overall pretty pleasant to work with.

<br/>Some ideas for future work:

<ul>

<li><a href="https://github.com/Dieterbe/influx-cli/issues/2">bulk insert performance could be better</a></li>

<li>once <a href="https://github.com/influxdb/influxdb/issues/263">influxdb can report query execution time</a> and hopefully also serialization time, the timing output can be more useful.  Right now we can only measure query execution+serialization+network transfer time combined</li>

<li>my gut feeling says that using something like msgpack instead of json, and/or even streaming the resultset as it is being generated (instead of first building the entire result, then serializing it, then sending it over, then having the client deserialize the entire thing) could really help performance, not just here, but basically anywhere you interface with influxdb.  Though I don't have hard numbers on this yet.</li>

</p>



	</div>

	<footer class="entry-meta">
		<span class="tag-links">		
			
                <a href="http://localhost:1313//tags/monitoring/index.html" rel="tag">monitoring</a>
            
                <a href="http://localhost:1313//tags/golang/index.html" rel="tag">golang</a>
            
		</span>
	</footer>
</article> 

			
				<article class="post type-post status-publish format-standard hentry">

	
	<header class="entry-header">

	

		<div class="entry-meta">
			<span class="cat-links">
                
			</span>
		</div>

        <h1 class="entry-title"><a href="http://localhost:1313/post/beautiful_go_patterns_for_concurrent_access_to_shared_resources_and_coordinating_responses/">Beautiful Go patterns for concurrent access to shared resources and coordinating responses</a></h1>

		<div class="entry-meta">
			<span class="entry-date">
				<a href="http://localhost:1313/post/beautiful_go_patterns_for_concurrent_access_to_shared_resources_and_coordinating_responses/" rel="bookmark">
					<time class="entry-date" datetime="2014-07-26 13:22:32 -0400 EDT">
						July 26, 2014
					</time>
				</a>
			</span>
		</div>

	</header>
	
	<div class="entry-content">
		<p>

It's a pretty common thing in backend go programs to have multiple coroutines concurrently needing to modify a shared resource,

and needing a response that tells them whether the operation succeeded and/or other auxiliary information.

Something centralized manages the shared state, the changes to it and the responses.

</p>

<!--more-->



<p>

This is effectively two things.

</p>



<h2>Pattern one: making access to thread-unsafe data structures thread safe</h2>

<p>

Making modifications to thread-unsafe data (remember, maps for example are not thread safe in go) in a thread safe way, you can use a select loop that reads

from various channels and enforces that all operations are executed serially, because only one select case can happen at the same time.

I saw this first in <a href="https://github.com/bitly/statsdaemon/blob/master/statsdaemon.go#L90">bitly's statsdaemon</a> and have since used this in various places, including <a href="https://github.com/vimeo/statsdaemon">vimeo/statsdaemon</a> and <a href="https://github.com/graphite-ng/carbon-relay-ng">carbon-relay-ng</a>, for example to route metrics (which needs read access to the routes map) while allowing changes to the routes (coming from the telnet admin interface), by having those as two cases in a select statement.  This was my first "aha!" moment.

</p>



<h2>pattern two: coordinating flow of responses</h2>

<p>

For the second, after (potentially time consuming) work, returning a response to the invoker, (let's say in the carbon-relay-ng case where you want to notify whether the route change succeeded) I have so far just passed on references to the admin interface session along with the request, and after completion of the work it would spawn a new goroutine that resumes the session with the given response.  Not the most elegant, but it works.

</p>



<p>

The other day though, I saw a very interesting pattern for this case. I don't remember where (probably one of the gophercon presentations)

or what it's called. 

But the idea is you can simply use one shared channel for all requests, and one shared channel for all responses.

As long as the requesters write a request to the requests channel and then read a response from the other channel, and the coordinator first reads a request and then writes the response, no further synchronization is needed.  Here's a demo program:

</p>



<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%">&lt;![CDATA[

<span style="color: #008000; font-weight: bold">package</span> main



<span style="color: #408080; font-style: italic">// demo the fact that we can just use one shared req and one resp channel.</span>

<span style="color: #408080; font-style: italic">// as long as they are unbuffered, the synchronization works just fine.</span>



<span style="color: #008000; font-weight: bold">import</span> <span style="color: #BA2121">&quot;fmt&quot;</span>

<span style="color: #008000; font-weight: bold">import</span> <span style="color: #BA2121">&quot;sync&quot;</span>

<span style="color: #008000; font-weight: bold">import</span> <span style="color: #BA2121">&quot;math/rand&quot;</span>

<span style="color: #008000; font-weight: bold">import</span> <span style="color: #BA2121">&quot;time&quot;</span>



<span style="color: #008000; font-weight: bold">var</span> requests = <span style="color: #008000">make</span>(<span style="color: #008000; font-weight: bold">chan</span> <span style="color: #B00040">int</span>)

<span style="color: #008000; font-weight: bold">var</span> responses = <span style="color: #008000">make</span>(<span style="color: #008000; font-weight: bold">chan</span> <span style="color: #B00040">string</span>)



<span style="color: #008000; font-weight: bold">func</span> routine(num <span style="color: #B00040">int</span>, wg <span style="color: #666666">*</span>sync.WaitGroup) {

    <span style="color: #408080; font-style: italic">// pretend this is a routine that&#39;s doing something, like serving a user session</span>

    <span style="color: #408080; font-style: italic">// but then we need to modify some shared state</span>

    time.Sleep(time.Duration(rand.Intn(<span style="color: #666666">100</span>)) <span style="color: #666666">*</span> time.Millisecond)

    requests <span style="color: #666666">&lt;-</span> num

    resp <span style="color: #666666">:=</span> <span style="color: #666666">&lt;-</span>responses

    fmt.Printf(<span style="color: #BA2121">&quot;routine %d gets response: %s\n&quot;</span>, num, resp)

    wg.Done()

}



<span style="color: #008000; font-weight: bold">func</span> coordinator() {

    <span style="color: #008000; font-weight: bold">for</span> {

        req <span style="color: #666666">:=</span> <span style="color: #666666">&lt;-</span>requests

        <span style="color: #408080; font-style: italic">// in here, you can do whatever modifications to shared state you need.</span>

        time.Sleep(time.Duration(rand.Intn(<span style="color: #666666">100</span>)) <span style="color: #666666">*</span> time.Millisecond) <span style="color: #408080; font-style: italic">// simulate some heavy lifting</span>

        responses <span style="color: #666666">&lt;-</span> fmt.Sprintf(<span style="color: #BA2121">&quot;this return value is meant for routine %d&quot;</span>, req)

    }

}



<span style="color: #008000; font-weight: bold">func</span> main() {

    <span style="color: #008000; font-weight: bold">go</span> coordinator()



    <span style="color: #008000; font-weight: bold">var</span> wg sync.WaitGroup

    <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #666666">:=</span> <span style="color: #666666">0</span>; i &lt; <span style="color: #666666">10</span>; i<span style="color: #666666">++</span> {

        wg.Add(<span style="color: #666666">1</span>)

        <span style="color: #008000; font-weight: bold">go</span> routine(i, <span style="color: #666666">&amp;</span>wg)

    }

    wg.Wait()

    <span style="color: #008000">close</span>(requests)

}

]]&gt;
</pre></div>




<a href="http://play.golang.org/p/32BSXT0xhN">code on Go playground</a>



<p>

At first glance, it looked as if the seemingly arbitrary reading and writing from/to channels without explicit synchronization would introduce race conditions, with routines getting

the response meant for other routines.  But after some reasoning, it becomes apparent that 

the "channel operation as synchronization" keeps everything under control, in a pretty elegant way.

<b>There is nothing explicit to assure the routines get their response, and not the response meant for another routine.

Instead, it just flows naturally and implicitly from the ordering of the blocked channel operations.</b>.

Another "aha!" moment for me.  I've heard "use channel operations for synchronization" often enough, and this is the most

beautiful example of it I've come across so far.  The routines are blocked on channel reads and writes, but when a channel operation occurs, that's where the respective goroutines unblock, and everything just works the way it's supposed to.  How elegant!

</p>



<h2>Conclusion</h2>

<p>

Maybe these patterns are obvious to you, maybe they are widely known patterns.

But I think as you evolve from go rookie to experienced developer (and often need to wrap your head around new concepts and approaches)

you will encounter some interesting patterns and also have your "aha!" moments, so I hope this will help someone.

</p>



<p>

I've been using the first pattern in a few places, I haven't used the second one yet, but I know some places where I can apply it and simplify some code.

Take for example this <a href="https://github.com/graphite-ng/carbon-relay-ng/pull/7">pull request to add a web UI to carbon-relay-ng</a>, now the metrics-router, the admin telnet interface, <b>and</b> the new http interface will all need access to the routes map.  I'm looking forward to implement the second pattern, simplifying the code while making it more generic at the same time.

</p>

	</div>

	<footer class="entry-meta">
		<span class="tag-links">		
			
                <a href="http://localhost:1313//tags/golang/index.html" rel="tag">golang</a>
            
		</span>
	</footer>
</article> 

			
				<article class="post type-post status-publish format-standard hentry">

	
	<header class="entry-header">

	

		<div class="entry-meta">
			<span class="cat-links">
                
			</span>
		</div>

        <h1 class="entry-title"><a href="http://localhost:1313/post/on-graphite-whisper-and-influxdb/">On Graphite, Whisper and InfluxDB</a></h1>

		<div class="entry-meta">
			<span class="entry-date">
				<a href="http://localhost:1313/post/on-graphite-whisper-and-influxdb/" rel="bookmark">
					<time class="entry-date" datetime="2014-05-18 13:22:32 -0400 EDT">
						May 18, 2014
					</time>
				</a>
			</span>
		</div>

	</header>
	
	<div class="entry-content">
		<h4>Graphite, and the storage Achilles heel</h4>



Graphite is a neat timeseries metrics storage system that comes with a powerful querying api, mainly due to the whole bunch of <a href="http://graphite.readthedocs.org/en/latest/functions.html">available processing functions</a>.

<br/>For medium to large setups, the storage aspect quickly becomes a pain point.  Whisper, the default graphite storage format, is a simple storage format, using one file per metric (timeseries).

<!--more-->

<ul>

<li>It can't keep all file descriptors in memory so there's a lot of overhead in constantly opening, seeking, and closing files, especially since usually one write comes in for all metrics at the same time.

</li>

<li>Using the rollups feature (different data resolutions based on age) causes a lot of extra IO.</li>

<li>The format is also simply not optimized for writes.  Carbon, the storage agent that sits in front of whisper has a feature to batch up writes to files to make them more sequential but this doesn't seem to help much.</li>

<li>Worse, due to various <a href="https://github.com/pcn/carbon/blob/new-sending-mechanism/Why_Spooling.md#what-problems-have-we-had">implementation details</a> the carbon agent is surprisingly inefficient and even cpu-bound.  People often run into cpu limitations before they hit the io bottleneck.  Once the writeback queue hits a certain size, carbon will blow up.</li>

</ul>

Common recommendations are to <a href="http://bitprophet.org/blog/2013/03/07/graphite/">run multiple carbon agents</a> and

<a href="http://obfuscurity.com/2012/04/Unhelpful-Graphite-Tip-5">running graphite on SSD drives</a>.

<br/>If you want to scale out across multiple systems, you can get carbon to shard metrics across multiple nodes, but the complexity can get out of hand and manually maintaining a cluster where nodes get added, fail, get phased out, need recovery, etc involves a lot of manual labor even though <a href="https://github.com/jssjr/carbonate/">carbonate</a> makes this easier.  This is a path I simply don't want to go down.

<br/>

<br/>

<p>

<i>These might be reasonable solutions based on the circumstances (often based on short-term local gains), but I believe as a community we should solve the problem at its root, so that everyone can reap the long term benefits.

</i>

</p>

<br/>



In particular, <a href="http://blog.sweetiq.com/2013/01/using-ceres-as-the-back-end-database-to-graphite/#axzz324uQtk3d">running Ceres instead of whisper</a>, is only a slight improvement, that suffers from most of the same problems.  I don't see any good reason to keep working on Ceres, other than perhaps that it's a fun exercise.   This probably explains the slow pace of development.

<br/>However, many mistakenly believe Ceres is "the future".

<br/><a href="http://www.inmobi.com/blog/2014/01/24/extending-graphites-mileage">Switching to LevelDB</a> seems much more sensible but IMHO still doesn't cut it as a general purpose, scalable solution.



<h4>The ideal backend</h4>

I believe we can build a backend for graphite that

<ul>

<li>can easily scale from a few metrics on my laptop in power-save mode to millions of metrics on a highly loaded cluster</li>

<li>supports nodes joining and leaving at runtime and automatically balancing the load across them</li>

<li>assures high availability and heals itself in case of disk or node failures</li>

<li>is simple to deploy.  think: just run an executable that knows which directories it can use for storage, elasticsearch-style automatic clustering, etc.</li>

<li>has the right read/write optimizations.  I've never seen a graphite system that is not write-focused, so something like <a href="http://en.wikipedia.org/wiki/Log-structured_merge-tree">LSM trees</a> seems to make a lot of sense.</li>

<li>can leverage cpu resources (e.g. for compression)</li>

<li>provides a more natural model for phasing out data.  Optional, runtime-changeable rollups.  And an age limit (possibly, but not necessarily round robin)

</ul>



While we're at it. pub-sub for realtime analytics would be nice too.  Especially when it allows to use the same functions as the query api.

<br/>And getting rid of the metric name restrictions such as inability to use dots or slashes.  Efficient sparse series support would be nice too.



<h4>InfluxDB</h4>



There's a lot of databases that you could hook up to graphite.

riak, hdfs based (opentsdb), Cassandra based (kairosdb, blueflood, cyanite), etc.



Some of these are solid and production ready, and would make sense depending on what you already have and have experience with.

I'm personally very interested in playing with Riak, but decided to choose InfluxDB as my first victim.

<br/>

<br/>

InfluxDB is a young project that will need time to build maturity, but is on track to meet all my goals very well.

In particular, installing it is a breeze (no dependencies), it's specifically built for timeseries (not based on a general purpose database),

which allows them to do a bunch of simplifications and optimizations, is write-optimized, and should meet my goals for scalability, performance, and availability well.

And they're in NYC so meeting up for lunch has proven to be pretty fruitful for both parties.  I'm pretty confident that these guys can pull off something big.

<br/>

<br/>

Technically, InfluxDB is a "timeseries, metrics, and analytics" databases with use cases well beyond graphite and even technical operations.

Like the alternative databases, graphite-like behaviors such as rollups management and automatically picking the series in the most appropriate resolutions, is something to be implemented on top of it.  Although you never know, it might end up being natively supported.





<h4>Graphite + InfluxDB</h4>



InfluxDB developers plan to implement a whole bunch of processing functions (akin to graphite, except they can do locality optimizations) and add a dashboard that talks to InfluxDB natively (or use <a href="http://grafana.org/">Grafana</a>), which means at some point you could completely swap graphite for InfluxDB.



However, I think for quite a while, the ability to use the Graphite api, combine backends, and use various graphite dashboards is still very useful.

So here's how my setup currently works:



<ul>

<li>

<a href="https://github.com/graphite-ng/carbon-relay-ng">carbon-relay-ng</a> is a carbon relay in Go.  

It's a pretty nifty program to partition and manage carbon metrics streams.  I use it in front of our traditional graphite system, and have it stream - in realtime - a copy of a subset of our metrics into InfluxDB.  This way I basically have our unaltered Graphite system, and in parallel to it, InfluxDB, containing a subset of the same data.

<br/>With a bit more work it will be a high performance alternative to the python carbon relay, allowing you to manage your streams on the fly.

It doesn't support consistent hashing, because CH should be part of a strategy of a highly available storage system (see requirements above), using CH in the relay still results in a poor storage system, so there's no need for it.

</li>

<li>I contributed the code to InfluxDB to make it listen on the carbon protocol.  So basically, for the purpose of ingestion, InfluxDB can look and act just like a graphite server.  Anything that can write to graphite, can now write to InfluxDB.  (assuming the plain-text protocol, it doesn't support the pickle protocol, which I think is a thing to avoid anyway because almost nothing supports it and you can't debug what's going on)</li>

<li><a href="https://github.com/brutasse/graphite-api">graphite-api</a> is a fork/clone of graphite-web, stripped of needless dependencies, stripped of the composer.  It's conceived for many of the same reasons behind <a href="http://dieter.plaetinck.be/graphite-ng_a-next-gen-graphite-server-in-go.html">graphite-ng</a> (graphite technical debt, slow development pace, etc) though it doesn't go to such extreme lengths and for now focuses on being a robust alternative for the graphite server, api-compatible, trivial to install and with a faster pace of development.

</li>

<li>

That's where <a href="https://github.com/vimeo/graphite-influxdb">graphite-influxdb</a> comes in.  It hooks InfluxDB into graphite-api, so that you can query the graphite api, but using data in InfluxDB.

It should also work with the regular graphite, though I've never tried.  (I have no incentive to bother with that, because I don't use the composer.  And I think it makes more sense to move the composer into a separate project anyway).

</li>

</ul>



With all these parts in place, I can run our dashboards next to each other - one running on graphite with whisper, one on graphite-api with InfluxDB - and simply look whether the returned data matches up, and which dashboards loads graphs faster.

Later i might do more extensive benchmarking and acceptance testing.

<br/>

<br/>

If all goes well, I can make carbon-relay-ng fully mirror all data, make graphite-api/InfluxDB the primary, and turn our old graphite box into a live "backup".

We'll need to come up with something for rollups and deletions of old data (although it looks like by itself influx is already more storage efficient than whisper too), and I'm really looking forward to the InfluxDB team building out the function api, having the same function api available for historical querying as well as realtime pub-sub.  (my goal used to be implementing this in graphite-ng and/or carbon-relay-ng, but if they do this well, I might just abandon graphite-ng)



<br/>

<br/>To be continued..



	</div>

	<footer class="entry-meta">
		<span class="tag-links">		
			
                <a href="http://localhost:1313//tags/devops/index.html" rel="tag">devops</a>
            
                <a href="http://localhost:1313//tags/monitoring/index.html" rel="tag">monitoring</a>
            
                <a href="http://localhost:1313//tags/golang/index.html" rel="tag">golang</a>
            
                <a href="http://localhost:1313//tags/perf/index.html" rel="tag">perf</a>
            
		</span>
	</footer>
</article> 

			
				<article class="post type-post status-publish format-standard hentry">

	
	<header class="entry-header">

	

		<div class="entry-meta">
			<span class="cat-links">
                
			</span>
		</div>

        <h1 class="entry-title"><a href="http://localhost:1313/post/pixie/">Pixie: simple photo management using directory layouts and tags.</a></h1>

		<div class="entry-meta">
			<span class="entry-date">
				<a href="http://localhost:1313/post/pixie/" rel="bookmark">
					<time class="entry-date" datetime="2013-12-30 14:46:32 -0400 -0400">
						December 30, 2013
					</time>
				</a>
			</span>
		</div>

	</header>
	
	<div class="entry-content">
		So you have a few devices with pictures, and maybe some additional pictures your friends sent you.  You have a lot of pictures of the same thing and probably too high of a resolution.  Some may require some editing.  How do you easily create photo albums out of this mess?  And how do you do it in a way

that keeps a simple and elegant, yet flexible file/directory layout for portability and simplicity?

<!--more-->

<br/>

<br/>I couldn't find a tool that I liked, so I rolled my own: <a href="https://github.com/Dieterbe/pixie">Pixie</a>.

<br/>

It gives you vim-like keybindings to navigate pictures, create edits (stored in a "mirror directory") and add/remove tags to pictures.  (Because n:m tag relationships are basically a must for organizing things and don't work on any common filesystem)

To generate "album" directories, just define which tags they should(n't) match and run the script that synchronizes an export directory by symlinking (or resizing) the correct files into them.

Note the source directory stays unaltered so you can easily keep syncing with devices and/or people.

<br/>What used to be a pain in the butt for me is now a pretty pleasant experience.

<br/>Does this workflow make sense to you? Is this useful to you? Why (not) ?

	</div>

	<footer class="entry-meta">
		<span class="tag-links">		
			
                <a href="http://localhost:1313//tags/arch/index.html" rel="tag">arch</a>
            
                <a href="http://localhost:1313//tags/golang/index.html" rel="tag">golang</a>
            
                <a href="http://localhost:1313//tags/photos/index.html" rel="tag">photos</a>
            
		</span>
	</footer>
</article> 

			
				<article class="post type-post status-publish format-standard hentry">

	
	<header class="entry-header">

	

		<div class="entry-meta">
			<span class="cat-links">
                
			</span>
		</div>

        <h1 class="entry-title"><a href="http://localhost:1313/post/graphite-ng_a-next-gen-graphite-server-in-go/">Graphite-ng: A next-gen graphite server in Go.</a></h1>

		<div class="entry-meta">
			<span class="entry-date">
				<a href="http://localhost:1313/post/graphite-ng_a-next-gen-graphite-server-in-go/" rel="bookmark">
					<time class="entry-date" datetime="2013-09-07 20:54:20 -0400 EDT">
						September 7, 2013
					</time>
				</a>
			</span>
		</div>

	</header>
	
	<div class="entry-content">
		<p>

I've been a <a href="https://github.com/graphite-project/">graphite</a> contributor for a while (and still am).  It's a <i>great</i> tool for timeseries metrics.

Two weeks ago I started working on <a href="https://github.com/graphite-ng/graphite-ng">Graphite-ng</a>:

it's somewhere between an early clone/rewrite, a redesign, and an experiment playground, written in <a href="http://golang.org">Golang</a>.

The focus of my work so far is the API web server, which is a functioning prototype, it answers requests like</p>

<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span style="color: #666666">&lt;!</span>[CDATA[

<span style="color: #BB6688">/render/</span><span style="color: #666666">?</span>target<span style="color: #666666">=</span>sum(scale(stats.web2,<span style="color: #666666">5.12</span>),derivative(stats.web2))

]]<span style="color: #666666">&gt;</span>
</pre></div>


<p>

I.e. it lets you retrieve your timeseries, processed by function pipelines which are setup on the fly based on a spec in your http/rest arguments.

Currently it only fetches metrics from text files but I'm working on decent metrics storage as well.

</p>

<!--more-->



<p>

There's a few reasons why I decided to start a new project from scratch:

<ul>

<li>With graphite, it's a whole ordeal to get all components properly installed.  Deploying in production environments is annoying and even more so

when you just want a graphite setup on your personal netbook.</li>

<li>the graphite development process slows contributors down a lot.  A group of 3rd/4th generation maintainers jointly manages the project, but it's hard to get big changes through,

because they (understandably) don't feel authoritative enough to judge those changes and the predecessors have disappeared or are too busy with other things.  And also ...</li>

<li>there's a high focus on backwards compatibility, which can be a good thing, but it's hard to get rid of old design mistakes,

especially when fixing unclear (but arguably broken) early design decisions (or oversights) lead to different outputs</li>

<li>Graphite suffers feature creep: it has an events system, a PNG renderer, an elaborate composer web UI, etc.

There's a lot of internal code dependencies holding you back from focusing on a specific problem</li>

<li>Carbon (the metrics daemon) has a pretty hard performance and scalability ceiling.

<a href="https://github.com/pcn/carbon/blob/new-sending-mechanism/Why_Spooling.md">Peter's article explains this well</a>; I think we'll need some form of

rewrite.   Peter suggests some solutions but they are basically workarounds for Python's shortcomings.  I'm also thinking of using <a href="http://pypy.org/">pypy</a>.

But last time I checked pypy just wasn't there yet.</li>

<li>I want to become a good Go programmer</li>

</ul>



<i>Note: the Graphite project is still great</i>, the people managing do good work, but it's fairly natural for a code base that large and complicated

to end up in this situation.<i>I'm not at all claiming graphite-ng is, or ever will be better</i> but I need a fresh start to try some disruptive ideas,

using Go means having a runtime very suited for concurrency and parallelism, you can compile the whole thing down into a single executable file,

and its performance looks promising.  Leaving out the non-essentials (see below) allows for an elegant and surprisingly small, hackable code base.

</p>



<p>

The API server I developed sets up a processing pipeline as directed by your query: every processing function runs in a goroutine

for concurrency and the metrics flow through using Go channels.  It literally compiles a program and executes it.  You can add your own functions

to collect, process, and return metrics by writing simple plugins.

<br/>As for timeseries storage, for now it uses simple text files,

but I'm experimenting and thinking what would be the best metric store(s) that works on small scale

(personal netbook install) to large scale ("I have millions of metrics that need to be distributed across nodes,

the system should be HA and self-healing in failure scenarios, easily maintainable, and highly performant") and is still easy to deploy, configure and run.

Candidates are <a href="https://github.com/kisielk/whisper-go">whisper-go</a>, <a href="https://code.google.com/p/kairosdb/">kairosdb</a>,

my own <a href="https://github.com/graphite-ng/graphite-ng/tree/master/carbon-es">elasticsearch experiment</a> etc.

<br/>I won't implement rendering images, because I think client-side rendering using something like <a href="https://github.com/vimeo/timeserieswidget">timeserieswidget</a>

is superior.  I can also leave out events because <a href="https://github.com/Dieterbe/anthracite/">anthracite</a> already does that.

There's a ton of dashboards out there (<a href="http://vimeo.github.io/graph-explorer/">graph-explorer</a>, <a href="https://github.com/obfuscurity/descartes">descartes</a>, <a href="http://graphite.readthedocs.org/en/1.0/tools.html">etc</a>) so that can be left out as well.

</p>



For more information, see <a href="https://github.com/graphite-ng/graphite-ng">the Graphite-ng homepage</a>.

<br/>

<br/>PS: props to <a href="http://felixge.de/">Felix Geisendorfer</a> who suggested a graphite clone in Go first,

it seemed like a huge undertaking but the right thing to do, I had some time so I went for it!

	</div>

	<footer class="entry-meta">
		<span class="tag-links">		
			
                <a href="http://localhost:1313//tags/devops/index.html" rel="tag">devops</a>
            
                <a href="http://localhost:1313//tags/monitoring/index.html" rel="tag">monitoring</a>
            
                <a href="http://localhost:1313//tags/golang/index.html" rel="tag">golang</a>
            
                <a href="http://localhost:1313//tags/perf/index.html" rel="tag">perf</a>
            
		</span>
	</footer>
</article> 

			
		
		</div>
	</div>
	<div id="secondary">

	

	<div id="primary-sidebar" class="primary-sidebar widget-area" role="complementary">

        

        

		<aside id="categories-3" class="widget widget_categories">


    
     


    <br/>
	<h1 class="widget-title">Popular tags</h1>

    <a href="http://localhost:1313/tags/monitoring">monitoring</a>
    24
    <br/>
    <a href="http://localhost:1313/tags/devops">devops</a>
    22
    <br/>
    <a href="http://localhost:1313/tags/golang">golang</a>
    8
    <br/>
    <br/>
    <br/>

	<h1 class="widget-title">Other tags</h1>

    
        
            <a href="http://localhost:1313/tags/arch">arch</a>
            19
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/bash">bash</a>
            15
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/cakephp">cakephp</a>
            8
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/conf">conf</a>
            9
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/dauth">dauth</a>
            1
            <br/>
        
    
        
        
    
        
            <a href="http://localhost:1313/tags/drums">drums</a>
            1
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/drupal">drupal</a>
            5
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/foss">foss</a>
            45
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/git">git</a>
            3
            <br/>
        
    
        
        
    
        
            <a href="http://localhost:1313/tags/information-age">information-age</a>
            3
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/life">life</a>
            32
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/linux">linux</a>
            20
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/lua">lua</a>
            1
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/mail">mail</a>
            1
            <br/>
        
    
        
        
    
        
            <a href="http://localhost:1313/tags/music">music</a>
            5
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/mysql">mysql</a>
            3
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/n900">n900</a>
            2
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/netlog">netlog</a>
            6
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/openstack">openstack</a>
            1
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/perf">perf</a>
            10
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/photos">photos</a>
            3
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/php">php</a>
            11
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/productivity">productivity</a>
            6
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/python">python</a>
            5
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/real-life">real-life</a>
            2
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/thesis">thesis</a>
            3
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/travel">travel</a>
            2
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/uzbl">uzbl</a>
            6
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/vimeo">vimeo</a>
            3
            <br/>
        
    
        
            <a href="http://localhost:1313/tags/web2.0">web2.0</a>
            9
            <br/>
        
    
</aside>


	</div>

</div>

</div>

		</div>

		<footer id="colophon" class="site-footer" role="contentinfo">

			<div class="site-info">
				<a href="http://gohugo.io">Proudly powered by Hugo</a>
			</div>
		</footer>
	</div>

	<script type='text/javascript' src='http://localhost:1313//js/functions.js'></script>
<script>document.write('<script src="http://'
        + (location.host || 'localhost').split(':')[0]
		+ ':1313/livereload.js?mindelay=10"></'
        + 'script>')</script></body>
</html>
