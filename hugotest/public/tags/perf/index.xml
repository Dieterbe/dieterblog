<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Perf on Dieter&#39;s blog</title>
    <link>http://localhost:1313/tags/perf/</link>
    <description>Recent content in Perf on Dieter&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 18 May 2014 13:22:32 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/perf/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>On Graphite, Whisper and InfluxDB</title>
      <link>http://localhost:1313/post/on-graphite-whisper-and-influxdb/</link>
      <pubDate>Sun, 18 May 2014 13:22:32 -0400</pubDate>
      
      <guid>http://localhost:1313/post/on-graphite-whisper-and-influxdb/</guid>
      <description>&lt;h4&gt;Graphite, and the storage Achilles heel&lt;/h4&gt;



Graphite is a neat timeseries metrics storage system that comes with a powerful querying api, mainly due to the whole bunch of &lt;a href=&#34;http://graphite.readthedocs.org/en/latest/functions.html&#34;&gt;available processing functions&lt;/a&gt;.

&lt;br/&gt;For medium to large setups, the storage aspect quickly becomes a pain point.  Whisper, the default graphite storage format, is a simple storage format, using one file per metric (timeseries).

&lt;!--more--&gt;

&lt;ul&gt;

&lt;li&gt;It can&#39;t keep all file descriptors in memory so there&#39;s a lot of overhead in constantly opening, seeking, and closing files, especially since usually one write comes in for all metrics at the same time.

&lt;/li&gt;

&lt;li&gt;Using the rollups feature (different data resolutions based on age) causes a lot of extra IO.&lt;/li&gt;

&lt;li&gt;The format is also simply not optimized for writes.  Carbon, the storage agent that sits in front of whisper has a feature to batch up writes to files to make them more sequential but this doesn&#39;t seem to help much.&lt;/li&gt;

&lt;li&gt;Worse, due to various &lt;a href=&#34;https://github.com/pcn/carbon/blob/new-sending-mechanism/Why_Spooling.md#what-problems-have-we-had&#34;&gt;implementation details&lt;/a&gt; the carbon agent is surprisingly inefficient and even cpu-bound.  People often run into cpu limitations before they hit the io bottleneck.  Once the writeback queue hits a certain size, carbon will blow up.&lt;/li&gt;

&lt;/ul&gt;

Common recommendations are to &lt;a href=&#34;http://bitprophet.org/blog/2013/03/07/graphite/&#34;&gt;run multiple carbon agents&lt;/a&gt; and

&lt;a href=&#34;http://obfuscurity.com/2012/04/Unhelpful-Graphite-Tip-5&#34;&gt;running graphite on SSD drives&lt;/a&gt;.

&lt;br/&gt;If you want to scale out across multiple systems, you can get carbon to shard metrics across multiple nodes, but the complexity can get out of hand and manually maintaining a cluster where nodes get added, fail, get phased out, need recovery, etc involves a lot of manual labor even though &lt;a href=&#34;https://github.com/jssjr/carbonate/&#34;&gt;carbonate&lt;/a&gt; makes this easier.  This is a path I simply don&#39;t want to go down.

&lt;br/&gt;

&lt;br/&gt;

&lt;p&gt;

&lt;i&gt;These might be reasonable solutions based on the circumstances (often based on short-term local gains), but I believe as a community we should solve the problem at its root, so that everyone can reap the long term benefits.

&lt;/i&gt;

&lt;/p&gt;

&lt;br/&gt;



In particular, &lt;a href=&#34;http://blog.sweetiq.com/2013/01/using-ceres-as-the-back-end-database-to-graphite/#axzz324uQtk3d&#34;&gt;running Ceres instead of whisper&lt;/a&gt;, is only a slight improvement, that suffers from most of the same problems.  I don&#39;t see any good reason to keep working on Ceres, other than perhaps that it&#39;s a fun exercise.   This probably explains the slow pace of development.

&lt;br/&gt;However, many mistakenly believe Ceres is &#34;the future&#34;.

&lt;br/&gt;&lt;a href=&#34;http://www.inmobi.com/blog/2014/01/24/extending-graphites-mileage&#34;&gt;Switching to LevelDB&lt;/a&gt; seems much more sensible but IMHO still doesn&#39;t cut it as a general purpose, scalable solution.



&lt;h4&gt;The ideal backend&lt;/h4&gt;

I believe we can build a backend for graphite that

&lt;ul&gt;

&lt;li&gt;can easily scale from a few metrics on my laptop in power-save mode to millions of metrics on a highly loaded cluster&lt;/li&gt;

&lt;li&gt;supports nodes joining and leaving at runtime and automatically balancing the load across them&lt;/li&gt;

&lt;li&gt;assures high availability and heals itself in case of disk or node failures&lt;/li&gt;

&lt;li&gt;is simple to deploy.  think: just run an executable that knows which directories it can use for storage, elasticsearch-style automatic clustering, etc.&lt;/li&gt;

&lt;li&gt;has the right read/write optimizations.  I&#39;ve never seen a graphite system that is not write-focused, so something like &lt;a href=&#34;http://en.wikipedia.org/wiki/Log-structured_merge-tree&#34;&gt;LSM trees&lt;/a&gt; seems to make a lot of sense.&lt;/li&gt;

&lt;li&gt;can leverage cpu resources (e.g. for compression)&lt;/li&gt;

&lt;li&gt;provides a more natural model for phasing out data.  Optional, runtime-changeable rollups.  And an age limit (possibly, but not necessarily round robin)

&lt;/ul&gt;



While we&#39;re at it. pub-sub for realtime analytics would be nice too.  Especially when it allows to use the same functions as the query api.

&lt;br/&gt;And getting rid of the metric name restrictions such as inability to use dots or slashes.  Efficient sparse series support would be nice too.



&lt;h4&gt;InfluxDB&lt;/h4&gt;



There&#39;s a lot of databases that you could hook up to graphite.

riak, hdfs based (opentsdb), Cassandra based (kairosdb, blueflood, cyanite), etc.



Some of these are solid and production ready, and would make sense depending on what you already have and have experience with.

I&#39;m personally very interested in playing with Riak, but decided to choose InfluxDB as my first victim.

&lt;br/&gt;

&lt;br/&gt;

InfluxDB is a young project that will need time to build maturity, but is on track to meet all my goals very well.

In particular, installing it is a breeze (no dependencies), it&#39;s specifically built for timeseries (not based on a general purpose database),

which allows them to do a bunch of simplifications and optimizations, is write-optimized, and should meet my goals for scalability, performance, and availability well.

And they&#39;re in NYC so meeting up for lunch has proven to be pretty fruitful for both parties.  I&#39;m pretty confident that these guys can pull off something big.

&lt;br/&gt;

&lt;br/&gt;

Technically, InfluxDB is a &#34;timeseries, metrics, and analytics&#34; databases with use cases well beyond graphite and even technical operations.

Like the alternative databases, graphite-like behaviors such as rollups management and automatically picking the series in the most appropriate resolutions, is something to be implemented on top of it.  Although you never know, it might end up being natively supported.





&lt;h4&gt;Graphite + InfluxDB&lt;/h4&gt;



InfluxDB developers plan to implement a whole bunch of processing functions (akin to graphite, except they can do locality optimizations) and add a dashboard that talks to InfluxDB natively (or use &lt;a href=&#34;http://grafana.org/&#34;&gt;Grafana&lt;/a&gt;), which means at some point you could completely swap graphite for InfluxDB.



However, I think for quite a while, the ability to use the Graphite api, combine backends, and use various graphite dashboards is still very useful.

So here&#39;s how my setup currently works:



&lt;ul&gt;

&lt;li&gt;

&lt;a href=&#34;https://github.com/graphite-ng/carbon-relay-ng&#34;&gt;carbon-relay-ng&lt;/a&gt; is a carbon relay in Go.  

It&#39;s a pretty nifty program to partition and manage carbon metrics streams.  I use it in front of our traditional graphite system, and have it stream - in realtime - a copy of a subset of our metrics into InfluxDB.  This way I basically have our unaltered Graphite system, and in parallel to it, InfluxDB, containing a subset of the same data.

&lt;br/&gt;With a bit more work it will be a high performance alternative to the python carbon relay, allowing you to manage your streams on the fly.

It doesn&#39;t support consistent hashing, because CH should be part of a strategy of a highly available storage system (see requirements above), using CH in the relay still results in a poor storage system, so there&#39;s no need for it.

&lt;/li&gt;

&lt;li&gt;I contributed the code to InfluxDB to make it listen on the carbon protocol.  So basically, for the purpose of ingestion, InfluxDB can look and act just like a graphite server.  Anything that can write to graphite, can now write to InfluxDB.  (assuming the plain-text protocol, it doesn&#39;t support the pickle protocol, which I think is a thing to avoid anyway because almost nothing supports it and you can&#39;t debug what&#39;s going on)&lt;/li&gt;

&lt;li&gt;&lt;a href=&#34;https://github.com/brutasse/graphite-api&#34;&gt;graphite-api&lt;/a&gt; is a fork/clone of graphite-web, stripped of needless dependencies, stripped of the composer.  It&#39;s conceived for many of the same reasons behind &lt;a href=&#34;http://dieter.plaetinck.be/graphite-ng_a-next-gen-graphite-server-in-go.html&#34;&gt;graphite-ng&lt;/a&gt; (graphite technical debt, slow development pace, etc) though it doesn&#39;t go to such extreme lengths and for now focuses on being a robust alternative for the graphite server, api-compatible, trivial to install and with a faster pace of development.

&lt;/li&gt;

&lt;li&gt;

That&#39;s where &lt;a href=&#34;https://github.com/vimeo/graphite-influxdb&#34;&gt;graphite-influxdb&lt;/a&gt; comes in.  It hooks InfluxDB into graphite-api, so that you can query the graphite api, but using data in InfluxDB.

It should also work with the regular graphite, though I&#39;ve never tried.  (I have no incentive to bother with that, because I don&#39;t use the composer.  And I think it makes more sense to move the composer into a separate project anyway).

&lt;/li&gt;

&lt;/ul&gt;



With all these parts in place, I can run our dashboards next to each other - one running on graphite with whisper, one on graphite-api with InfluxDB - and simply look whether the returned data matches up, and which dashboards loads graphs faster.

Later i might do more extensive benchmarking and acceptance testing.

&lt;br/&gt;

&lt;br/&gt;

If all goes well, I can make carbon-relay-ng fully mirror all data, make graphite-api/InfluxDB the primary, and turn our old graphite box into a live &#34;backup&#34;.

We&#39;ll need to come up with something for rollups and deletions of old data (although it looks like by itself influx is already more storage efficient than whisper too), and I&#39;m really looking forward to the InfluxDB team building out the function api, having the same function api available for historical querying as well as realtime pub-sub.  (my goal used to be implementing this in graphite-ng and/or carbon-relay-ng, but if they do this well, I might just abandon graphite-ng)



&lt;br/&gt;

&lt;br/&gt;To be continued..


</description>
    </item>
    
    <item>
      <title>Graphite-ng: A next-gen graphite server in Go.</title>
      <link>http://localhost:1313/post/graphite-ng_a-next-gen-graphite-server-in-go/</link>
      <pubDate>Sat, 07 Sep 2013 20:54:20 -0400</pubDate>
      
      <guid>http://localhost:1313/post/graphite-ng_a-next-gen-graphite-server-in-go/</guid>
      <description>&lt;p&gt;

I&#39;ve been a &lt;a href=&#34;https://github.com/graphite-project/&#34;&gt;graphite&lt;/a&gt; contributor for a while (and still am).  It&#39;s a &lt;i&gt;great&lt;/i&gt; tool for timeseries metrics.

Two weeks ago I started working on &lt;a href=&#34;https://github.com/graphite-ng/graphite-ng&#34;&gt;Graphite-ng&lt;/a&gt;:

it&#39;s somewhere between an early clone/rewrite, a redesign, and an experiment playground, written in &lt;a href=&#34;http://golang.org&#34;&gt;Golang&lt;/a&gt;.

The focus of my work so far is the API web server, which is a functioning prototype, it answers requests like&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #BB6688&#34;&gt;/render/&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;?&lt;/span&gt;target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;sum(scale(stats.web2,&lt;span style=&#34;color: #666666&#34;&gt;5.12&lt;/span&gt;),derivative(stats.web2))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;

I.e. it lets you retrieve your timeseries, processed by function pipelines which are setup on the fly based on a spec in your http/rest arguments.

Currently it only fetches metrics from text files but I&#39;m working on decent metrics storage as well.

&lt;/p&gt;

&lt;!--more--&gt;



&lt;p&gt;

There&#39;s a few reasons why I decided to start a new project from scratch:

&lt;ul&gt;

&lt;li&gt;With graphite, it&#39;s a whole ordeal to get all components properly installed.  Deploying in production environments is annoying and even more so

when you just want a graphite setup on your personal netbook.&lt;/li&gt;

&lt;li&gt;the graphite development process slows contributors down a lot.  A group of 3rd/4th generation maintainers jointly manages the project, but it&#39;s hard to get big changes through,

because they (understandably) don&#39;t feel authoritative enough to judge those changes and the predecessors have disappeared or are too busy with other things.  And also ...&lt;/li&gt;

&lt;li&gt;there&#39;s a high focus on backwards compatibility, which can be a good thing, but it&#39;s hard to get rid of old design mistakes,

especially when fixing unclear (but arguably broken) early design decisions (or oversights) lead to different outputs&lt;/li&gt;

&lt;li&gt;Graphite suffers feature creep: it has an events system, a PNG renderer, an elaborate composer web UI, etc.

There&#39;s a lot of internal code dependencies holding you back from focusing on a specific problem&lt;/li&gt;

&lt;li&gt;Carbon (the metrics daemon) has a pretty hard performance and scalability ceiling.

&lt;a href=&#34;https://github.com/pcn/carbon/blob/new-sending-mechanism/Why_Spooling.md&#34;&gt;Peter&#39;s article explains this well&lt;/a&gt;; I think we&#39;ll need some form of

rewrite.   Peter suggests some solutions but they are basically workarounds for Python&#39;s shortcomings.  I&#39;m also thinking of using &lt;a href=&#34;http://pypy.org/&#34;&gt;pypy&lt;/a&gt;.

But last time I checked pypy just wasn&#39;t there yet.&lt;/li&gt;

&lt;li&gt;I want to become a good Go programmer&lt;/li&gt;

&lt;/ul&gt;



&lt;i&gt;Note: the Graphite project is still great&lt;/i&gt;, the people managing do good work, but it&#39;s fairly natural for a code base that large and complicated

to end up in this situation.&lt;i&gt;I&#39;m not at all claiming graphite-ng is, or ever will be better&lt;/i&gt; but I need a fresh start to try some disruptive ideas,

using Go means having a runtime very suited for concurrency and parallelism, you can compile the whole thing down into a single executable file,

and its performance looks promising.  Leaving out the non-essentials (see below) allows for an elegant and surprisingly small, hackable code base.

&lt;/p&gt;



&lt;p&gt;

The API server I developed sets up a processing pipeline as directed by your query: every processing function runs in a goroutine

for concurrency and the metrics flow through using Go channels.  It literally compiles a program and executes it.  You can add your own functions

to collect, process, and return metrics by writing simple plugins.

&lt;br/&gt;As for timeseries storage, for now it uses simple text files,

but I&#39;m experimenting and thinking what would be the best metric store(s) that works on small scale

(personal netbook install) to large scale (&#34;I have millions of metrics that need to be distributed across nodes,

the system should be HA and self-healing in failure scenarios, easily maintainable, and highly performant&#34;) and is still easy to deploy, configure and run.

Candidates are &lt;a href=&#34;https://github.com/kisielk/whisper-go&#34;&gt;whisper-go&lt;/a&gt;, &lt;a href=&#34;https://code.google.com/p/kairosdb/&#34;&gt;kairosdb&lt;/a&gt;,

my own &lt;a href=&#34;https://github.com/graphite-ng/graphite-ng/tree/master/carbon-es&#34;&gt;elasticsearch experiment&lt;/a&gt; etc.

&lt;br/&gt;I won&#39;t implement rendering images, because I think client-side rendering using something like &lt;a href=&#34;https://github.com/vimeo/timeserieswidget&#34;&gt;timeserieswidget&lt;/a&gt;

is superior.  I can also leave out events because &lt;a href=&#34;https://github.com/Dieterbe/anthracite/&#34;&gt;anthracite&lt;/a&gt; already does that.

There&#39;s a ton of dashboards out there (&lt;a href=&#34;http://vimeo.github.io/graph-explorer/&#34;&gt;graph-explorer&lt;/a&gt;, &lt;a href=&#34;https://github.com/obfuscurity/descartes&#34;&gt;descartes&lt;/a&gt;, &lt;a href=&#34;http://graphite.readthedocs.org/en/1.0/tools.html&#34;&gt;etc&lt;/a&gt;) so that can be left out as well.

&lt;/p&gt;



For more information, see &lt;a href=&#34;https://github.com/graphite-ng/graphite-ng&#34;&gt;the Graphite-ng homepage&lt;/a&gt;.

&lt;br/&gt;

&lt;br/&gt;PS: props to &lt;a href=&#34;http://felixge.de/&#34;&gt;Felix Geisendorfer&lt;/a&gt; who suggested a graphite clone in Go first,

it seemed like a huge undertaking but the right thing to do, I had some time so I went for it!
</description>
    </item>
    
    <item>
      <title>Profiling and behavior testing of processes and daemons, and Devopsdays NYC</title>
      <link>http://localhost:1313/post/profiling_and_behavior_testing_processes_daemons_devopsdays_nyc/</link>
      <pubDate>Mon, 21 Jan 2013 15:25:14 -0400</pubDate>
      
      <guid>http://localhost:1313/post/profiling_and_behavior_testing_processes_daemons_devopsdays_nyc/</guid>
      <description>&lt;h3&gt;Profiling a process run&lt;/h3&gt;

&lt;a href=&#34;https://github.com/Dieterbe/profile-process&#34;&gt;

&lt;img style=&#34;float:left;margin:0 5px 0 0;&#34; src=&#34;http://localhost:1313/files/presentation-simple-black-box/images/profile_io.png&#34; width=&#34;100px&#34; height=&#34;100px&#34;/&gt;

&lt;/a&gt;

I wanted the ability to run a given process and get

&lt;br/&gt;a plot of key metrics (cpu usage, memory usage, disk i/o) throughout the duration of the process run.

&lt;br/&gt;Something light-weight with minimal dependencies so I can easily install it on a server for a one-time need.

&lt;br/&gt;Couldn&#39;t find a tool for it, so I wrote &lt;a href=&#34;https://github.com/Dieterbe/profile-process&#34;&gt;profile-process&lt;/a&gt;

&lt;br/&gt;which does exactly that in &lt;100 lines of python.

&lt;br/&gt;

&lt;br/&gt;



&lt;h3&gt;black-box behavior testing processes/daemons&lt;/h3&gt;

&lt;a href=&#34;https://github.com/vimeo/simple-black-box&#34;&gt;

&lt;img style=&#34;float:left;margin:0 5px 0 0;&#34; src=&#34;http://localhost:1313/files/presentation-simple-black-box/images/screenshot-no-pause.png&#34; width=&#34;150px&#34; height=&#34;100px&#34;/&gt;

&lt;/a&gt;

I wrote &lt;a href=&#34;https://github.com/vimeo/simple-black-box&#34;&gt;simple-black-box&lt;/a&gt; to do this.

&lt;br/&gt;It runs the subject(s) in a crafted sandbox, sends input (http requests, commands, ...)

&lt;br/&gt;and allows to make assertions on http/statsd requests/responses, network listening state, processes running, log entries,

&lt;br/&gt;file existence/checksums in the VFS/swift clusters, etc.

&lt;br/&gt;Each test-case is a scenario.

&lt;br/&gt;It also can use &lt;a href=&#34;http://logstash.net/&#34;&gt;logstash&lt;/a&gt; to give a centralized &#34;distributed stack trace&#34; when you need to debug a failure after

multiple processes interacting and acting upon received messages; or to compare behavior across different scenario runs.

&lt;br/&gt;You can integrate this with profile-process to compare runtime behaviors across testcases/scenarios.

&lt;!--more--&gt;



&lt;h3&gt;Simple-black-box talk @ Devopsdays NYC&lt;/h3&gt;

I did a quick &lt;a href=&#34;http://devopsdays.org/events/2012-newyork/proposals/SimpleBlackBox/&#34;&gt;5min talk&lt;/a&gt;, despite some display/timing issues it was well received.

(in particular I got some really positive feedback from one person and still wonder if that was a recruiter attempting to

hire me -but being shy about it...- it was quite awkward)

&lt;br/&gt;&amp;rarr; &lt;a href=&#34;http://localhost:1313/files/presentation-simple-black-box/slideshow.html&#34;&gt;slides&lt;/a&gt;

&lt;br/&gt;&amp;rarr; &lt;a href=&#34;http://new.livestream.com/devopsdaysorg/nyc2013/videos/9609498&#34;&gt;raw uncut video&lt;/a&gt;.  Go to &#39;New York, January 18th, 2013&#39; from 02:36:25 to 02:41:15



&lt;h3&gt;More random thoughts about Devopsdays NYC&lt;/h3&gt;

&lt;center&gt;&lt;a href=&#34;http://devopsdays.org/events/2012-newyork/&#34;&gt;&lt;img src=&#34;http://localhost:1313/files/blog/devopsdays/workers.png&#34; width=&#34;300px&#34; height=&#34;300px&#34;/&gt;&lt;/a&gt;&lt;/center&gt;

&lt;ul&gt;

&lt;li&gt;I&#39;m getting tired of people on stage making a big revelation out of adding an index to a database column.

This happens too often at web-ops/devops conferences,  it&#39;s embarrassing.

But at least it&#39;s not like the &#34;how we made our site 1000x faster&#34;-style Velocity talks that should have been named &#34;caching and query optimization for newbies&#34;

&lt;/li&gt;

&lt;li&gt;Paperless post confirms again they got their act together and keeps us up to date with their great work.

&lt;a href=&#34;http://dev.paperlesspost.com/&#34;&gt;Follow them.&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;

&lt;a href=&#34;http://devopsdays.org/events/2012-newyork/proposals/KnightsOftheProvisioningRoundTable/&#34;&gt;Knights of the Provisioning Round Table - Bare Metal Provisioning&lt;/a&gt;

was mostly (to my surprise) 4 individuals presenting their solution instead of a real round-table, but (to my surprise again) they were not as similar/repetitive as I expected

and the pros/cons of all solutions were compared more in depth than I dared to hope.

I &lt;a href=&#34;http://localhost:1313/dell_crowbar_openstack_swift.html&#34;&gt;covered dell crowbar before&lt;/a&gt; and like it, though I wonder when this thing is actually gonna be reliable.

&lt;/li&gt;

&lt;li&gt;Dave Zwieback and John Willis gave hilarious talks&lt;/li&gt;

&lt;li&gt;Tried to start an open space discussion around &lt;b&gt;collaboration patterns and anti-patterns&lt;/b&gt;, which I think is a very interesting subject,

  because &lt;b&gt;how individuals in a team collaborate is crucial to success&lt;/b&gt;, but yet very little is written about it (that I could find).

  I would hope we can distill the years of aggregate experience of people into concise patterns and anti-patterns and document how (not) well they work

  for development styles (such as agile/scrum), team size, company structure/hierarchy, roadmap/technical debt pressure, etc.  And especially in light

  of any of these things changing, because I&#39;ve found &lt;b&gt;people can be very change-resistive&lt;/b&gt;.

&lt;/li&gt;

&lt;li&gt;&lt;a href=&#34;http://devopsdays.org/events/2012-newyork/proposals/DevopsAtObamaForAmerica/&#34;&gt;DevOps At Obama for America &amp; The Democratic National Committee&lt;/a&gt;

was good, I thought it would be a rehash of what was said at &lt;a href=&#34;http://codeforward_newyorkcity.eventbrite.com/&#34;&gt;Coding Forward New York City: Meet the Developers Behind the Obama Campaign&lt;/a&gt;

but there were a bunch of interesting insights about state of the art technology in here (mostly Amazon stuff)&lt;/li&gt;

&lt;li&gt;A bunch of talks where the same could have been said in half the time, or less&lt;/li&gt;

&lt;/ul&gt;

Random thoughts about some sponsors: 

&lt;ul&gt;

&lt;li&gt;Librato is quite cool.

It&#39;s basically how my open source tool &lt;a href=&#34;https://github.com/vimeo/graph-explorer&#34;&gt;graph-explorer&lt;/a&gt; would look like after

finishing a bunch of TODO&#39;s, combining it with graphite, polishing it all up, and offering it as a hosted solution.

I find it interesting if this is a successful business with only such a limited scope&lt;/li&gt;

&lt;li&gt;

Even cooler is &lt;a href=&#34;http://www.datadoghq.com/&#34;&gt;datadog&lt;/a&gt;.  It goes beyond just metrics and doesn&#39;t just provide hosted graphing,

it provides a solution for a philosophy that aims for a centralized insight of all your operational data,

related collaboration and prioritized alerts that are to the point.  They get a lot of things right, the open source world has some catching up to do&lt;/li&gt;

&lt;/ul&gt;

Interesting that both use Cassandra and free-form tags for flexibility, validating the approach I&#39;m taking with graph-explorer.  Now Graphite

could use a distributed metrics storage backend over which one can do map-reduce style jobs to gather intelligence from metrics archives

(maybe based on Cassandra too?), but that&#39;s another story.

&lt;br/&gt;

&lt;br/&gt;

Anyway, living in NYC with its vibrant ecosystem of devops people and companies organizing plenty of meet-ups and talks on their own

makes it less pressing to have an event like Devopsdays, though it was certainly a good event, thanks to the sponsors and the volunteers.
</description>
    </item>
    
    <item>
      <title>Histograms in statsd, and graphing them over time with graphite.</title>
      <link>http://localhost:1313/post/histogram-statsd-graphing-over-time-with-graphite/</link>
      <pubDate>Wed, 07 Nov 2012 18:45:11 -0400</pubDate>
      
      <guid>http://localhost:1313/post/histogram-statsd-graphing-over-time-with-graphite/</guid>
      <description>&lt;p&gt;

I submitted a pull request to statsd which adds &lt;a href=&#34;https://github.com/etsy/statsd/pull/162&#34;&gt;histogram support&lt;/a&gt;.

&lt;img style=&#34;float:left;margin:0 5px 0 0;&#34; src=&#34;http://localhost:1313/files/Black_cherry_tree_histogram.svg.png&#34; alt=&#34;Example histogram, from Wikipedia&#34;/&gt;

&lt;br/&gt;(refresher: a histogram is [a visualization of] a frequency distribution of data,

paraphrasing your data by keeping frequencies for entire classes (ranges of data).

&lt;a href=&#34;http://en.wikipedia.org/wiki/Histogram&#34;&gt;histograms - Wikipedia&lt;/a&gt;)

&lt;br/&gt;It&#39;s commonly documented how to plot single histograms, that is a 2D diagram consisting of rectangles whose

&lt;ul&gt;

&lt;li&gt;area is proportional to the frequency of a variable&lt;/li&gt;

&lt;li&gt;whose width is equal to the class interval&lt;/li&gt;

&lt;/ul&gt;

Class intervals go on x-axis, frequencies on y-axis.

&lt;br/&gt;

&lt;br/&gt;

Note: histogram class intervals are supposed to have the same width.

&lt;br/&gt;My implementation allows arbitrary class intervals with potentially different widths,

as well as an upper boundary of infinite.

&lt;/p&gt;

&lt;h4&gt;Plotting histograms.. over time&lt;/h4&gt;

&lt;!--more--&gt;

&lt;p&gt;

We want to plot histograms over time, and not just for a few select points in time (in which case you can just make several histograms),

but a contiguous range of time, preferably through graphite&#39;s 2D graphs cause graphite is neat and common enough.

&lt;br/&gt;Time goes on x-axis, that&#39;s pretty much a given.  So I&#39;m trying to explore ways to visualize both class intervals as well as frequencies on the y-axis.

&lt;/p&gt;

&lt;p&gt;The example I&#39;ll use are page rendering timings, condensed into classes with upper boundaries of 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50 and infinite seconds&lt;/p&gt;

&lt;p&gt;

Tips and notes:

&lt;ul&gt;

&lt;li&gt;

the histogram implementation stores absolute frequencies, but it&#39;s easy to get relative frequencies in percent, like so:

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;scale(divideSeries(stats.timers.&lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt;your_metric&lt;span style=&#34;color: #666666&#34;&gt;&amp;gt;&lt;/span&gt;.bin_&lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt;,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;

&lt;li&gt;I&#39;ll be using relative frequencies here because it normalizes the scale of the y-axis&lt;/li&gt;

&lt;li&gt;In this use case each class has a notion of desirability (&lt;i&gt;low render time good, high render time bad&lt;/i&gt;),

&lt;br/&gt;I think it makes sense to use color to represent this.  This extends to a lot of operational metrics which one would be using histograms for.

&lt;br/&gt;(unlike non-software histograms that represent demographics or tree heights, where classes usually have nothing to do with desirability or quality).

&lt;br/&gt;As it turns out, it&#39;s fairly easy to programmatically compute colors between green and red in order to have mathematically correct &#34;steps&#34; of color.

&lt;br/&gt;However, &lt;a href=&#34;http://stackoverflow.com/questions/340209/generate-colors-between-red-and-green-for-a-power-meter&#34;&gt;Looks like HSV values are more suited

than RGB&lt;/a&gt; but &lt;a href=&#34;https://github.com/graphite-project/graphite-web/issues/93&#34;&gt;

graphite doesn&#39;t support HSV (yet)&lt;/a&gt; (although one could convert HSV to RGB).

Also &lt;a href=&#34;http://vis4.net/blog/posts/goodbye-redgreen-scales/&#34;&gt;it looks like

green-purple would be a better choice for people with color blindness&lt;/a&gt;.  I haven&#39;t gone too far in this topic.

&lt;/li&gt;

&lt;li&gt;Since I choose to go with color gradients, it means I better use stacked graphs, otherwise it would be too hard to distinguish which graph is what&lt;/li&gt;

&lt;li&gt;None of this is restricted to timing data.  The metric type under which histograms are (and should be) implemented is called &#34;timing&#34;, which is

a misleading name but &lt;a href=&#34;https://github.com/etsy/statsd/issues/98&#34;&gt;we&#39;re working on renaming it&lt;/a&gt;.&lt;/li&gt;

&lt;/ul&gt;





&lt;h4&gt;First version&lt;/h4&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;http&lt;span style=&#34;color: #666666&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//localhost:9000/render/?height=300&amp;amp;&lt;/span&gt;

width&lt;span style=&#34;color: #666666&#34;&gt;=740&amp;amp;&lt;/span&gt;from&lt;span style=&#34;color: #666666&#34;&gt;=-24&lt;/span&gt;h&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;title&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;Render time histogram&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

vtitle&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;relative frequency &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;%&amp;amp;&lt;/span&gt;yMax&lt;span style=&#34;color: #666666&#34;&gt;=100&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_0_01,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;2FFF00&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;0.01&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_0_05,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;64DD0E&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;0.05&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_0_1,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;9CDD0E&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;0.1&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_0_5,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;DDCC0E&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;0.5&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_1,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;DDB70E&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;1&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_5,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;FF6200&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;5&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_10,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;FF3C00&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;10&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_50,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;FF1E00&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;50&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_inf,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;FF0000&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;inf&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

lineMode&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;slope&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;areaMode&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;stacked&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;drawNullAsZero&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;hideLegend&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;false&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;img src=&#34;http://localhost:1313/files/rendertime-histogram.png&#34; width=&#34;740&#34; height=&#34;300&#34; alt=&#34;rendertime histogram&#34; /&gt;

&lt;br/&gt;Turns out we mainly see the vast majority that performs well, simply because with this way of rendering,

the higher the frequency of a class, the more prominent.  Bad values are hard to see because there&#39;s not many of them,

despite being more interesting.

A thought I had at this point was to make all &#34;class bands&#34; equally wide and use a green-to-red gradient to denote the frequency values,

or even just keep the current color assignments but rely on something like opacity to express frequencies. Alas, none of this is currently

possible with graphite, as far as I can tell.  Though I would like to explore this further.  Especially because I think it wouldn&#39;t be hard to implement

in graphite.

&lt;br/&gt;

&lt;br/&gt;

So, let&#39;s see what &lt;i&gt;can&lt;/i&gt; be done right now.



&lt;h4&gt;Leaving out the smallest class&lt;/h4&gt;

This adaption is basically the same as before, but leaves out the smallest class (which took most space), this way

the other bands are a bit more visible but the effect isn&#39;t as clear as we want.

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;http&lt;span style=&#34;color: #666666&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//localhost:9000/render/?height=300&amp;amp;&lt;/span&gt;

width&lt;span style=&#34;color: #666666&#34;&gt;=740&amp;amp;&lt;/span&gt;from&lt;span style=&#34;color: #666666&#34;&gt;=-24&lt;/span&gt;h&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;title&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;Render time histogram&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

vtitle&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;relative frequency &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;%&lt;/span&gt;, leaving out first &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_0_05,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;64DD0E&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;0.05&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_0_1,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;9CDD0E&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;0.1&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_0_5,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;DDCC0E&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;0.5&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_1,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;DDB70E&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;1&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_5,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;FF6200&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;5&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_10,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;FF3C00&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;10&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_50,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;FF1E00&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;50&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_inf,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;100&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;FF0000&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;inf&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

lineMode&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;slope&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;areaMode&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;stacked&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;drawNullAsZero&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;hideLegend&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;false&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;img src=&#34;http://localhost:1313/files/rendertime-histogram-leaving-out-first-class.png&#34; width=&#34;740&#34; height=&#34;300&#34; alt=&#34;rendertime histogram leaving out first class&#34; /&gt;



&lt;h4&gt;Per-band scaling&lt;/h4&gt;

Finally, the bigger the values represented by each class the more we inflate the band,

so the more problematic cases become more visible, despite having a lower frequency.

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;http&lt;span style=&#34;color: #666666&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//localhost:9000/render/?height=300&amp;amp;&lt;/span&gt;

width&lt;span style=&#34;color: #666666&#34;&gt;=740&amp;amp;&lt;/span&gt;from&lt;span style=&#34;color: #666666&#34;&gt;=-24&lt;/span&gt;h&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;title&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;Render time histogram&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

vtitle&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;rel. freq &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;with&lt;/span&gt; scale adjustment per band&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_0_01,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;0.01&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;2FFF00&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;0.01&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_0_05,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;0.04&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;64DD0E&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;0.05&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_0_1,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;0.05&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;9CDD0E&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;0.1&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_0_5,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;0.4&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;DDCC0E&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;0.5&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_1,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;0.5&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;DDB70E&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;1&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_5,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;4&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;FF6200&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;5&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_10,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;5&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;FF3C00&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;10&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_50,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;40&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;FF1E00&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;50&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

target&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;alias(color(scale(divideSeries(stats.timers.render_time.bin_inf,stats.timers.render_time.count),&lt;span style=&#34;color: #666666&#34;&gt;60&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;FF0000&amp;#39;&lt;/span&gt;),&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;inf&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;

lineMode&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;slope&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;areaMode&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;stacked&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;drawNullAsZero&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;hideLegend&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;false&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;img src=&#34;http://localhost:1313/files/rendertime-histogram-higher-focus-for-higher-class-interval.png&#34; width=&#34;740&#34; height=&#34;300&#34; alt=&#34;rendertime histogram with higher focus for higher class interval&#34; /&gt;

&lt;br/&gt;I started off by scaling each band by the width of the class interval.  This is actually more arbitrary than it may seem.

&lt;br/&gt;The point is that now it&#39;s easier to spot acute as well as long-standing problems, but note you can&#39;t really read statistics from this graph because of the per-band scaling.

&lt;br/&gt;Note also that outliers contribute to the outer band(s) and are given as much focus as non-outliers in the same bands.

In a system over which you have no complete control (i.e. if you were graphing histograms of time until first byte or page loaded at client,

where you rely on the internet as a transport) it makes sense to give less attention to outliers and focus on optimizing for as many users as possible,

I think it there&#39;s no reliable way to subtract outliers from the upper bands and you should also graph averages and percentiles and understand what each

graph does.

But anyway here I want to include outliers, because they represent latencies we can fix.



&lt;h4&gt;Final notes&lt;/h4&gt;

While the tools we have are by no means perfect, I&#39;m seeing gradual improvement in the monitoring space.  This work is only a small piece

of the puzzle. The rendering of histograms can be improved but at this point I think they are good enough to be usable. The real challenge is

putting in place automated trending, anomaly detection and alerting.  If we can figure that out, there&#39;s less need to be looking at graphs in the first place.
</description>
    </item>
    
    <item>
      <title>Poor mans pickle implementations benchmark</title>
      <link>http://localhost:1313/post/poor_mans_pickle_implementations_benchmark/</link>
      <pubDate>Thu, 16 Jun 2011 22:32:12 -0400</pubDate>
      
      <guid>http://localhost:1313/post/poor_mans_pickle_implementations_benchmark/</guid>
      <description>&lt;!--more--&gt;

&lt;p&gt;&lt;a href=&#34;http://nlp.fi.muni.cz/projekty/gensim/&#34;&gt;Gensim&lt;/a&gt; is a very cool python2, numpy-based vector space modelling (information retrieval) framework.  It does the job in a straightforward way, and it has been a great project for me to learn python with because it uses some nice tricks in real life scenarios (like Generators) and is AFAICT elegantly coded.  Sometimes I find it hard to believe how much functionality can be crammed in so few lines of (readable) code.&lt;/p&gt;



&lt;p&gt;But anyway we&#39;re having some issues in it with cPickle (it &lt;a href=&#34;https://github.com/piskvorky/gensim/issues/31&#34;&gt;breaks when saving large matrices&lt;/a&gt;, it &lt;a href=&#34;https://github.com/piskvorky/gensim/issues/30&#34;&gt;breaks with some objects&lt;/a&gt;).

For now I worked around it by using &lt;a href=&#34;http://jsonpickle.github.com/&#34;&gt;jsonpickle&lt;/a&gt; but I wonder how viable this alternative really is.&lt;/p&gt;



&lt;p&gt;To give at least a crude idea of performance characteristics of different pickle methods, I wrote a very simple benchmark program - &lt;a href=&#34;https://github.com/Dieterbe/picklebench&#34;&gt;picklebench&lt;/a&gt; - to compare pickle, cPickle and jsonpickle.

The script fills a dictionary which gets bigger and bigger, and for certain sizes of dictionary it is saved to, and loaded from disk again.  We measure some metrics of each step.

We continue until memory is exhausted.&lt;/p&gt;

&lt;!--more--&gt;

limitations of this benchmark:

&lt;ul&gt;

&lt;li&gt;effects of writing a new file, or overwriting existing file, and however the filesystem deals with that (efficiency, allocation of sectors on disk, etc) are ignored&lt;/li&gt;

&lt;li&gt;no explicit flushing or warming of Linux block cache, ignoring writeback caches. (but that should be okay: every write is treated the same way, and reads always benefit from warm block cache)&lt;/li&gt;

&lt;li&gt;I could ignore disk i/o by only doing serializing in memory, but that wouldn&#39;t be very realistic either, and speed is lower than sequential read/write speeds of my hard disk anyway&lt;/li&gt;

&lt;li&gt;other running processes are ignored. (but my pc was pretty much idle otherwise)&lt;/li&gt;

&lt;li&gt;all metrics are crude&lt;/li&gt;

&lt;li&gt;all single runs&lt;/li&gt;

&lt;li&gt;no garbage collection is being run. volatility of datastructures is completely ignored.  Assumes that measuring the RSS difference provides useful information.&lt;/li&gt;

&lt;li&gt;Other than the obvious cPickle, I did not bother to look up if optimized implementations for some things exist (like json decoders)&lt;/li&gt;

&lt;/ul&gt;

You can easily &lt;a href=&#34;https://github.com/Dieterbe/picklebench/blob/master/runall.sh&#34;&gt;run the program&lt;/a&gt; yourself, but here is the output I got, on my i3 540 @ 3.07GHz with 3GiB RAM.

&lt;pre&gt;

Testing JsonPickle

== 1000 ==

Stored in 0.01s. file size 0.05 MB. Speed 6.56 MB/s. RSS taken 0.23 MB. (4.34 MB per MB in file)

Loaded in 0.01s. Speed 9.30 MB/s. RSS taken 0.04 MB.  (0.71 MB per MB in file)

== 4000 ==

Stored in 0.03s. file size 0.21 MB. Speed 6.93 MB/s. RSS taken 0.45 MB. (2.16 MB per MB in file)

Loaded in 0.02s. Speed 9.54 MB/s. RSS taken 0.47 MB.  (2.23 MB per MB in file)

== 16000 ==

Stored in 0.13s. file size 0.85 MB. Speed 6.80 MB/s. RSS taken 0.86 MB. (1.00 MB per MB in file)

Loaded in 0.09s. Speed 9.55 MB/s. RSS taken 0.88 MB.  (1.04 MB per MB in file)

== 64000 ==

Stored in 0.50s. file size 3.44 MB. Speed 6.87 MB/s. RSS taken 4.02 MB. (1.17 MB per MB in file)

Loaded in 0.36s. Speed 9.44 MB/s. RSS taken 2.52 MB.  (0.73 MB per MB in file)

== 256000 ==

Stored in 2.10s. file size 13.97 MB. Speed 6.64 MB/s. RSS taken 17.24 MB. (1.23 MB per MB in file)

Loaded in 1.53s. Speed 9.15 MB/s. RSS taken 8.49 MB.  (0.61 MB per MB in file)

== 1024000 ==

Stored in 8.60s. file size 56.23 MB. Speed 6.54 MB/s. RSS taken 61.64 MB. (1.10 MB per MB in file)

Loaded in 6.27s. Speed 8.97 MB/s. RSS taken 95.99 MB.  (1.71 MB per MB in file)

== 4096000 ==

Stored in 38.80s. file size 228.26 MB. Speed 5.88 MB/s. RSS taken 181.83 MB. (0.80 MB per MB in file)

Loaded in 25.17s. Speed 9.07 MB/s. RSS taken 170.84 MB.  (0.75 MB per MB in file)

== 16384000 ==

Testing cPickle

Protocol 0

== 1000 ==

Stored in 0.01s. file size 0.01 MB. Speed 0.83 MB/s. RSS taken 0.05 MB. (5.95 MB per MB in file)

Loaded in 0.00s. Speed 9.02 MB/s. RSS taken 0.05 MB.  (5.04 MB per MB in file)

== 4000 ==

Stored in 0.00s. file size 0.04 MB. Speed 8.69 MB/s. RSS taken 0.10 MB. (2.52 MB per MB in file)

Loaded in 0.00s. Speed 15.43 MB/s. RSS taken 0.13 MB.  (3.26 MB per MB in file)

== 16000 ==

Stored in 0.01s. file size 0.17 MB. Speed 11.06 MB/s. RSS taken 0.13 MB. (0.79 MB per MB in file)

Loaded in 0.01s. Speed 16.82 MB/s. RSS taken 0.10 MB.  (0.60 MB per MB in file)

== 64000 ==

Stored in 0.06s. file size 0.69 MB. Speed 12.43 MB/s. RSS taken 0.12 MB. (0.17 MB per MB in file)

Loaded in 0.04s. Speed 17.25 MB/s. RSS taken 0.77 MB.  (1.11 MB per MB in file)

== 256000 ==

Stored in 0.22s. file size 2.96 MB. Speed 13.65 MB/s. RSS taken 0.18 MB. (0.06 MB per MB in file)

Loaded in 0.17s. Speed 17.49 MB/s. RSS taken 3.09 MB.  (1.04 MB per MB in file)

== 1024000 ==

Stored in 0.88s. file size 12.20 MB. Speed 13.93 MB/s. RSS taken 0.16 MB. (0.01 MB per MB in file)

Loaded in 0.69s. Speed 17.72 MB/s. RSS taken 12.38 MB.  (1.01 MB per MB in file)

== 4096000 ==

Stored in 3.52s. file size 52.14 MB. Speed 14.80 MB/s. RSS taken 0.05 MB. (0.00 MB per MB in file)

Loaded in 2.84s. Speed 18.37 MB/s. RSS taken 49.55 MB.  (0.95 MB per MB in file)

== 16384000 ==

Stored in 12.68s. file size 218.27 MB. Speed 17.22 MB/s. RSS taken 0.19 MB. (0.00 MB per MB in file)

Loaded in 11.59s. Speed 18.82 MB/s. RSS taken 198.20 MB.  (0.91 MB per MB in file)

Testing cPickle

Protocol 1

== 1000 ==

Stored in 0.00s. file size 0.00 MB. Speed 9.65 MB/s. RSS taken 0.05 MB. (11.10 MB per MB in file)

Loaded in 0.00s. Speed 9.31 MB/s. RSS taken 0.06 MB.  (12.81 MB per MB in file)

== 4000 ==

Stored in 0.00s. file size 0.02 MB. Speed 10.95 MB/s. RSS taken 0.10 MB. (4.95 MB per MB in file)

Loaded in 0.00s. Speed 11.15 MB/s. RSS taken 0.12 MB.  (6.19 MB per MB in file)

== 16000 ==

Stored in 0.02s. file size 0.08 MB. Speed 5.26 MB/s. RSS taken 0.13 MB. (1.64 MB per MB in file)

Loaded in 0.01s. Speed 11.77 MB/s. RSS taken 0.09 MB.  (1.13 MB per MB in file)

== 64000 ==

Stored in 0.03s. file size 0.32 MB. Speed 12.60 MB/s. RSS taken 0.12 MB. (0.37 MB per MB in file)

Loaded in 0.03s. Speed 11.48 MB/s. RSS taken 0.78 MB.  (2.43 MB per MB in file)

== 256000 ==

Stored in 0.10s. file size 1.66 MB. Speed 17.00 MB/s. RSS taken 0.18 MB. (0.11 MB per MB in file)

Loaded in 0.11s. Speed 14.50 MB/s. RSS taken 3.10 MB.  (1.86 MB per MB in file)

== 1024000 ==

Stored in 0.40s. file size 7.04 MB. Speed 17.76 MB/s. RSS taken 0.16 MB. (0.02 MB per MB in file)

Loaded in 0.45s. Speed 15.54 MB/s. RSS taken 12.39 MB.  (1.76 MB per MB in file)

== 4096000 ==

Stored in 1.59s. file size 28.55 MB. Speed 17.95 MB/s. RSS taken 0.05 MB. (0.00 MB per MB in file)

Loaded in 1.88s. Speed 15.20 MB/s. RSS taken 49.55 MB.  (1.74 MB per MB in file)

== 16384000 ==

Stored in 6.23s. file size 114.59 MB. Speed 18.40 MB/s. RSS taken 0.19 MB. (0.00 MB per MB in file)

Loaded in 7.18s. Speed 15.96 MB/s. RSS taken 198.21 MB.  (1.73 MB per MB in file)

Testing cPickle

Protocol 2

== 1000 ==

Stored in 0.00s. file size 0.00 MB. Speed 9.54 MB/s. RSS taken 0.05 MB. (11.10 MB per MB in file)

Loaded in 0.00s. Speed 8.92 MB/s. RSS taken 0.06 MB.  (12.81 MB per MB in file)

== 4000 ==

Stored in 0.00s. file size 0.02 MB. Speed 13.25 MB/s. RSS taken 0.10 MB. (4.95 MB per MB in file)

Loaded in 0.00s. Speed 11.39 MB/s. RSS taken 0.12 MB.  (6.19 MB per MB in file)

== 16000 ==

Stored in 0.01s. file size 0.08 MB. Speed 13.85 MB/s. RSS taken 0.13 MB. (1.64 MB per MB in file)

Loaded in 0.01s. Speed 10.77 MB/s. RSS taken 0.09 MB.  (1.13 MB per MB in file)

== 64000 ==

Stored in 0.02s. file size 0.32 MB. Speed 13.99 MB/s. RSS taken 0.12 MB. (0.37 MB per MB in file)

Loaded in 0.03s. Speed 11.45 MB/s. RSS taken 0.78 MB.  (2.43 MB per MB in file)

== 256000 ==

Stored in 0.10s. file size 1.66 MB. Speed 16.81 MB/s. RSS taken 0.18 MB. (0.11 MB per MB in file)

Loaded in 0.12s. Speed 14.31 MB/s. RSS taken 3.10 MB.  (1.86 MB per MB in file)

== 1024000 ==

Stored in 0.37s. file size 7.04 MB. Speed 19.15 MB/s. RSS taken 0.16 MB. (0.02 MB per MB in file)

Loaded in 0.45s. Speed 15.55 MB/s. RSS taken 12.39 MB.  (1.76 MB per MB in file)

== 4096000 ==

Stored in 1.58s. file size 28.55 MB. Speed 18.09 MB/s. RSS taken 0.05 MB. (0.00 MB per MB in file)

Loaded in 1.83s. Speed 15.61 MB/s. RSS taken 49.55 MB.  (1.74 MB per MB in file)

== 16384000 ==

Stored in 6.02s. file size 114.59 MB. Speed 19.04 MB/s. RSS taken 0.19 MB. (0.00 MB per MB in file)

Loaded in 7.32s. Speed 15.65 MB/s. RSS taken 198.21 MB.  (1.73 MB per MB in file)

Testing pickle

Protocol 0

== 1000 ==

Stored in 0.01s. file size 0.01 MB. Speed 1.17 MB/s. RSS taken 0.03 MB. (3.21 MB per MB in file)

Loaded in 0.04s. Speed 0.20 MB/s. RSS taken 0.06 MB.  (6.41 MB per MB in file)

== 4000 ==

Stored in 0.02s. file size 0.04 MB. Speed 1.91 MB/s. RSS taken 0.09 MB. (2.42 MB per MB in file)

Loaded in 0.02s. Speed 2.12 MB/s. RSS taken 0.12 MB.  (3.15 MB per MB in file)

== 16000 ==

Stored in 0.08s. file size 0.17 MB. Speed 2.00 MB/s. RSS taken 0.13 MB. (0.79 MB per MB in file)

Loaded in 0.07s. Speed 2.27 MB/s. RSS taken 0.09 MB.  (0.55 MB per MB in file)

== 64000 ==

Stored in 0.33s. file size 0.69 MB. Speed 2.08 MB/s. RSS taken 0.12 MB. (0.18 MB per MB in file)

Loaded in 0.29s. Speed 2.40 MB/s. RSS taken 0.77 MB.  (1.11 MB per MB in file)

== 256000 ==

Stored in 1.34s. file size 2.96 MB. Speed 2.21 MB/s. RSS taken 0.18 MB. (0.06 MB per MB in file)

Loaded in 1.17s. Speed 2.53 MB/s. RSS taken 3.09 MB.  (1.04 MB per MB in file)

== 1024000 ==

Stored in 5.33s. file size 12.20 MB. Speed 2.29 MB/s. RSS taken 0.16 MB. (0.01 MB per MB in file)

Loaded in 4.73s. Speed 2.58 MB/s. RSS taken 12.38 MB.  (1.01 MB per MB in file)

== 4096000 ==

Stored in 21.23s. file size 52.14 MB. Speed 2.46 MB/s. RSS taken 0.05 MB. (0.00 MB per MB in file)

Loaded in 18.63s. Speed 2.80 MB/s. RSS taken 49.55 MB.  (0.95 MB per MB in file)

== 16384000 ==

Stored in 85.09s. file size 218.27 MB. Speed 2.57 MB/s. RSS taken 0.19 MB. (0.00 MB per MB in file)

Loaded in 74.60s. Speed 2.93 MB/s. RSS taken 198.20 MB.  (0.91 MB per MB in file)

Testing pickle

Protocol 1

== 1000 ==

Stored in 0.01s. file size 0.00 MB. Speed 0.80 MB/s. RSS taken 0.06 MB. (11.96 MB per MB in file)

Loaded in 0.00s. Speed 1.56 MB/s. RSS taken 0.07 MB.  (14.52 MB per MB in file)

== 4000 ==

Stored in 0.02s. file size 0.02 MB. Speed 0.84 MB/s. RSS taken 0.10 MB. (4.95 MB per MB in file)

Loaded in 0.01s. Speed 1.65 MB/s. RSS taken 0.13 MB.  (6.61 MB per MB in file)

== 16000 ==

Stored in 0.09s. file size 0.08 MB. Speed 0.85 MB/s. RSS taken 0.13 MB. (1.64 MB per MB in file)

Loaded in 0.05s. Speed 1.68 MB/s. RSS taken 0.09 MB.  (1.13 MB per MB in file)

== 64000 ==

Stored in 0.38s. file size 0.32 MB. Speed 0.85 MB/s. RSS taken 0.10 MB. (0.32 MB per MB in file)

Loaded in 0.19s. Speed 1.67 MB/s. RSS taken 0.80 MB.  (2.51 MB per MB in file)

== 256000 ==

Stored in 1.49s. file size 1.66 MB. Speed 1.11 MB/s. RSS taken 0.19 MB. (0.11 MB per MB in file)

Loaded in 0.75s. Speed 2.21 MB/s. RSS taken 3.13 MB.  (1.88 MB per MB in file)

== 1024000 ==

Stored in 6.11s. file size 7.04 MB. Speed 1.15 MB/s. RSS taken 0.16 MB. (0.02 MB per MB in file)

Loaded in 2.99s. Speed 2.35 MB/s. RSS taken 12.45 MB.  (1.77 MB per MB in file)

== 4096000 ==

Stored in 24.40s. file size 28.55 MB. Speed 1.17 MB/s. RSS taken 0.06 MB. (0.00 MB per MB in file)

Loaded in 11.97s. Speed 2.39 MB/s. RSS taken 49.74 MB.  (1.74 MB per MB in file)

== 16384000 ==

Stored in 97.62s. file size 114.59 MB. Speed 1.17 MB/s. RSS taken 0.19 MB. (0.00 MB per MB in file)

Loaded in 48.04s. Speed 2.39 MB/s. RSS taken 198.88 MB.  (1.74 MB per MB in file)

Testing pickle

Protocol 2

== 1000 ==

Stored in 0.01s. file size 0.00 MB. Speed 0.78 MB/s. RSS taken 0.06 MB. (11.96 MB per MB in file)

Loaded in 0.00s. Speed 1.57 MB/s. RSS taken 0.07 MB.  (14.52 MB per MB in file)

== 4000 ==

Stored in 0.02s. file size 0.02 MB. Speed 0.85 MB/s. RSS taken 0.10 MB. (4.95 MB per MB in file)

Loaded in 0.01s. Speed 1.52 MB/s. RSS taken 0.13 MB.  (6.60 MB per MB in file)

== 16000 ==

Stored in 0.09s. file size 0.08 MB. Speed 0.85 MB/s. RSS taken 0.13 MB. (1.64 MB per MB in file)

Loaded in 0.05s. Speed 1.66 MB/s. RSS taken 0.09 MB.  (1.18 MB per MB in file)

== 64000 ==

Stored in 0.38s. file size 0.32 MB. Speed 0.85 MB/s. RSS taken 0.10 MB. (0.31 MB per MB in file)

Loaded in 0.19s. Speed 1.65 MB/s. RSS taken 0.80 MB.  (2.51 MB per MB in file)

== 256000 ==

Stored in 1.52s. file size 1.66 MB. Speed 1.09 MB/s. RSS taken 0.19 MB. (0.11 MB per MB in file)

Loaded in 0.76s. Speed 2.18 MB/s. RSS taken 3.13 MB.  (1.88 MB per MB in file)

== 1024000 ==

Stored in 6.19s. file size 7.04 MB. Speed 1.14 MB/s. RSS taken 0.16 MB. (0.02 MB per MB in file)

Loaded in 3.01s. Speed 2.34 MB/s. RSS taken 12.45 MB.  (1.77 MB per MB in file)

== 4096000 ==

Stored in 24.60s. file size 28.55 MB. Speed 1.16 MB/s. RSS taken 0.06 MB. (0.00 MB per MB in file)

Loaded in 12.06s. Speed 2.37 MB/s. RSS taken 49.74 MB.  (1.74 MB per MB in file)

== 16384000 ==

Stored in 98.38s. file size 114.59 MB. Speed 1.16 MB/s. RSS taken 0.19 MB. (0.00 MB per MB in file)

Loaded in 47.89s. Speed 2.39 MB/s. RSS taken 198.88 MB.  (1.74 MB per MB in file)

&lt;/pre&gt;

Paraphrased:

&lt;ul&gt;

&lt;li&gt;JsonPickle needs more RSS then pickle/cPickle, and runs out of memory sooner. all pickle/cPickle runs need the same RSS&lt;/li&gt;

&lt;li&gt;Protocol 1/2 need the same amount of diskspace, protocol 0 needs about the double, JsonPickle about 8 times more&lt;/li&gt;

&lt;li&gt;Protocol 1/2 are as fast, protocol 0 is slower. cPickle is speed king.  Jsonpickle is slow&lt;/li&gt;

&lt;/ul&gt;

Conclusion:

&lt;ul&gt;

&lt;li&gt;Use cPickle or pickle, unless they are broken for your use case(s)&lt;/li&gt;

&lt;li&gt;Consider persisting only your data in appropriate formats (textfile, database, ...). Often you don&#39;t really need to persist entire &lt;i&gt;objects&lt;/i&gt;.  In the case of Gensim, we can also work with numpy&#39;s dataformat.&lt;/li&gt;

&lt;li&gt;If you like json, or want a very simple workaround for cPickle/pickle brokenness, and you cannot use a more appropriate format (see above) consider jsonpickle&lt;/li&gt;

&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Rsyncbench, an rsync benchmarking tool</title>
      <link>http://localhost:1313/post/rsyncbench_an_rsync_benchmarking_tool/</link>
      <pubDate>Fri, 15 Oct 2010 09:38:12 -0400</pubDate>
      
      <guid>http://localhost:1313/post/rsyncbench_an_rsync_benchmarking_tool/</guid>
      <description>&lt;p&gt;Background info:&lt;br /&gt;

I&#39;m currently in the process of evaluating (V)PS hosting providers and backup solutions.  The idea being: I want a (V)PS to run my stuff, which doesn&#39;t need much disk space,&lt;br /&gt;

but in the meantime it might be a good idea to look for online backup solutions (oops did I say &#34;online&#34;? I meant &#34;cloud&#34;), like on the (V)PS itself, or maybe as a separate solution.&lt;br /&gt;

But I&#39;ve got some diverse amount of data (my personal data is mostly a lot of small plaintext files, my mom has a windows VM for which I considered syncing the entire vdi file)&lt;br /&gt;

At this point the biggest contenders are &lt;a href=&#34;http://linode.com/&#34;&gt;Linode&lt;/a&gt; (which offers quite some flexibility and management tools, but becomes expensive when you want extra disk space (2$/month*GB), &lt;a href=&#34;http://www.rackspace.com/apps/backup_and_collaboration/data_backup_software/&#34;&gt;Rackspace backup&lt;/a&gt; gives you 10GB for 5$/month, but they have nice backup tools so I could only backup the important files from within the windows VM (~200MB), and then there&#39;s &lt;a href=&#34;http://www.hetzner.de/&#34;&gt;Hetzner&lt;/a&gt;, which offers powerful physical private servers with a lot of storage (160GB) for 29eur/month, but less flexibility (I.e. kvm-over-ip costs an extra 15eur/month)&lt;/p&gt;

&lt;p&gt;Another issue, given the limited capacity of Belgian internet connections, I needed to figure out how much bandwith rsync really needs, so I can calculate if the duration of a backup run including syncing the full vdi file is still reasonable.&lt;/p&gt;

&lt;p&gt;I couldn&#39;t find an rsync benchmarking tool, so I wrote my own.&lt;/p&gt;

&lt;p&gt;Features:&lt;/p&gt;

&lt;ul&gt;

&lt;li&gt;simple&lt;/li&gt;

&lt;li&gt;non invasive: you specify the target and destination hosts (just localhost is fine too), and file locations&lt;/li&gt;

&lt;li&gt;measures time spent, bytes sent (measured with tcpdump), and data sent (rsync&#39;s statistics which takes compression into account)&lt;/li&gt;

&lt;li&gt;supports plugins&lt;/li&gt;

&lt;li&gt;generates png graphs using Gnuplot&lt;/li&gt;

&lt;li&gt;two current plugins: one using files of various sizes, both randomly generated (/dev/urandom) and easily compressable (/dev/zero), does some use cases like initial sync, second sync (no-op), and syncing with a data block appended and prepended.  The other plugin collects vdi files from rsnapshot directories and measures the rsyncing from each image to the next&lt;/li&gt;

&lt;/ul&gt;

&lt;p&gt;&lt;!--more--&gt;&lt;br /&gt;

Non-features:&lt;/p&gt;

&lt;ul&gt;

&lt;li&gt;no plugins yet for other use cases then my own (no file removal, renaming, working with multiple files, working with small files, ...)&lt;/li&gt;

&lt;li&gt;doesn&#39;t test a lot of different file sizes and such&lt;/li&gt;

&lt;li&gt;not as finished as my other projects (no Makefile, graphs are rough.  but I have no time to go dive further in the gnuplot stuff)

&lt;li&gt;the benchmarking process takes a long time, due to a lot of juggling with big files. some steps can be optimized&lt;/li&gt;

&lt;/ul&gt;

&lt;p&gt;Here is an example graph:&lt;br /&gt;

&lt;img src=&#34;http://localhost:1313/files/rsyncbench_random_images_sent.png&#34;/&gt;&lt;br /&gt;

The first entry on the x-asis is on 1MiB, even though it seems like 0MiB because of the scale.&lt;br /&gt;

Notice how rsync is pretty efficient when it has nothing to do (no-op), and the sizes of transmitted data correspond exactly to what has changed (even if you prepend data in the beginning and all data &#34;moves to the back&#34;, rsync notices this)&lt;br /&gt;

The compressed numbers (reported by rsync) are very close to the real numbers measured with tcpdump.  Which makes sense, random data is not easy to compress.  OTOH, if i take the graph of the case where I sync images which are built from /dev/zero, the story similar so either rsyncs compression sucks (which I find hard to believe), or the guy on #rsync who told me those numbers are about the compressed data was wrong (maybe) or I just messed up something (likely)&lt;/p&gt;

&lt;p&gt;So, I hope this is useful to someone, and maybe others can clone the project and improve it further.  I found it weird that I couldn&#39;t find an rsync benchmarking tool, because rsync&#39;s algorithm is non-obvious and it can be really interesting to understand all its characteristics in various use cases.&lt;/p&gt;

&lt;p&gt;Project page: &lt;a href=&#34;http://github.com/Dieterbe/rsyncbench&#34;&gt;rsyncbench on Github&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Oh and about my backups? Rsyncing the different vdi files takes upto a few hundreds of MB&#39;s, not an ideal solution given the upload speeds in Belgium.&lt;br /&gt;

I&#39;ll figure out something else.  Like backing up from inside windows (maybe using the rackspace service), or mounting the vdi and rsyncing the data from there.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>facebook usrbincrash php implementation</title>
      <link>http://localhost:1313/post/facebook_usrbincrash_php_implementation/</link>
      <pubDate>Fri, 12 Feb 2010 23:25:46 -0400</pubDate>
      
      <guid>http://localhost:1313/post/facebook_usrbincrash_php_implementation/</guid>
      <description>&lt;p&gt;Implementation for Facebook &lt;a href=&#34;http://www.facebook.com/careers/puzzles.php?puzzle_id=2&#34;&gt;usr bin crash&lt;/a&gt; puzzle. (&lt;a href=&#34;http://localhost:1313/not_working_for_facebook&#34;&gt;how/why&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;I haven&#39;t touched the code for a few months, but better to put it online then to let it rot.&lt;br /&gt;

&lt;a href=&#34;http://github.com/Dieterbe/facebookpuzzles/&#34; title=&#34;http://github.com/Dieterbe/facebookpuzzles/&#34;&gt;http://github.com/Dieterbe/facebookpuzzles/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2 branches:&lt;/p&gt;

&lt;ul&gt;

&lt;li&gt;master: basically what I submitted to FB, and what just works&lt;/li&gt;

&lt;li&gt;withpruning: an attempt for futher optimalisation (it only improves the runtime in some cases) but I didn&#39;t finish that version and there&#39;s a bug in it somewhere&lt;/li&gt;

&lt;/ul&gt;

&lt;p&gt;In the repo you&#39;ll also find various test input files supplied by the community on &lt;a href=&#34;http://www.facebook.com/topic.php?uid=15325934266&amp;amp;topic=5131&amp;amp;post=30091&#34;&gt;the forums&lt;/a&gt; and a script to benchmark the implementation on all inputfiles.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mysql status variables caveats</title>
      <link>http://localhost:1313/post/mysql_status_variables_caveats/</link>
      <pubDate>Sat, 06 Jun 2009 11:33:34 -0400</pubDate>
      
      <guid>http://localhost:1313/post/mysql_status_variables_caveats/</guid>
      <description>&lt;p&gt;While setting up Zenoss and reading &lt;a href=&#34;http://dev.mysql.com/doc/refman/5.0/en/server-status-variables.html&#34;&gt;Mysql documentation about status variables&lt;/a&gt; I learned:&lt;/p&gt;

&lt;ul&gt;

&lt;li&gt;All select_* variables (&#34;Select statistics&#34; graph in Zenoss) are actually about joins, not (all) selects.  This also explains why there is no clear relation to com_select (which shows the amount of selects).  (&#34;Command statistics:selects&#34; graph in Zenoss)&lt;/li&gt;

&lt;li&gt;Com_select does not denote all incoming select commands.  If you have a hit on your query cache, com_select is &lt;em&gt;not&lt;/em&gt; incremented.  So I thought we were doing less qps while in fact we were just getting more cache hits. Qcache_hits gets incremented on cache hits (but is not monitored by Zenoss)&lt;/li&gt;

&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Poor mans dmenu benchmark</title>
      <link>http://localhost:1313/post/poor_mans_dmenu_benchmark/</link>
      <pubDate>Sat, 25 Apr 2009 11:25:26 -0400</pubDate>
      
      <guid>http://localhost:1313/post/poor_mans_dmenu_benchmark/</guid>
      <description>&lt;p&gt;I wanted to know how responsive &lt;a href=&#34;http://tools.suckless.org/dmenu&#34;&gt;dmenu&lt;/a&gt; and awk, sort, uniq are on a 50MB file (625000 entries of 80 1-byte chars each).&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;generate file:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;#!/bin/bash&lt;/span&gt;

&lt;span style=&#34;color: #008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;Creating dummy file of 50MB in size (625000 entries of 80chars)&amp;quot;&lt;/span&gt;

&lt;span style=&#34;color: #008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;Note: this takes about an hour and a half&amp;quot;&lt;/span&gt;

&lt;span style=&#34;color: #19177C&#34;&gt;entries_per_iteration&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt;1000

&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; i in &lt;span style=&#34;color: #BA2121&#34;&gt;`&lt;/span&gt;seq &lt;span style=&#34;color: #666666&#34;&gt;1&lt;/span&gt; 625&lt;span style=&#34;color: #BA2121&#34;&gt;`&lt;/span&gt;

&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;do&lt;/span&gt;

        &lt;span style=&#34;color: #008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;Iteration &lt;/span&gt;&lt;span style=&#34;color: #19177C&#34;&gt;$i&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt; of 625 ( &lt;/span&gt;&lt;span style=&#34;color: #19177C&#34;&gt;$entries_per_iteration&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt; each )&amp;quot;&lt;/span&gt;

        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; j in &lt;span style=&#34;color: #BA2121&#34;&gt;`&lt;/span&gt;seq &lt;span style=&#34;color: #666666&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color: #19177C&#34;&gt;$entries_per_iteration&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;`&lt;/span&gt;

        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;do&lt;/span&gt;

                &lt;span style=&#34;color: #008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;`date +&amp;#39;%Y-%m-%d %H:%M:%S&amp;#39;` `date +%s`abcdefhijklmno`date +%s | md5sum`&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; ./dummy_history_file

        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;done&lt;/span&gt;

&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;measure speed:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;Plain awk &amp;#39;{print \$3}&amp;#39;:&amp;quot;&lt;/span&gt;

&lt;span style=&#34;color: #008000&#34;&gt;time &lt;/span&gt;awk &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;{print $3}&amp;#39;&lt;/span&gt; dummy_history_file &amp;gt;/dev/null



&lt;span style=&#34;color: #008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;awk + sort&amp;quot;&lt;/span&gt;

&lt;span style=&#34;color: #008000&#34;&gt;time &lt;/span&gt;awk &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;{print $3}&amp;#39;&lt;/span&gt; dummy_history_file | sort &amp;gt;/dev/null

&lt;span style=&#34;color: #008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;awk + sort + uniq&amp;quot;&lt;/span&gt;

&lt;span style=&#34;color: #008000&#34;&gt;time &lt;/span&gt;awk &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;{print $3}&amp;#39;&lt;/span&gt; dummy_history_file | sort | uniq &amp;gt;/dev/null



&lt;span style=&#34;color: #008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;Plain dmenu:&amp;quot;&lt;/span&gt;

dmenu &amp;lt; dummy_history_file

&lt;span style=&#34;color: #008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;awked into dmenu:&amp;quot;&lt;/span&gt;

awk &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;{print $3}&amp;#39;&lt;/span&gt; dummy_history_file | dmenu

&lt;span style=&#34;color: #008000&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;awk + sort + uniq into dmenu:&amp;quot;&lt;/span&gt;

awk &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;{print $3}&amp;#39;&lt;/span&gt; dummy_history_file | sort | uniq | dmenu
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;

Results.&lt;br /&gt;

I ran the test twice about an half hour after generating the file, so in the first run, the first awk call may have been affected by a no longer complete Linux block cache.&lt;br /&gt;

(I also edited the output format a bit)&lt;br /&gt;

Run 1:&lt;/p&gt;

&lt;pre&gt;

Plain awk &#39;{print $3}&#39;:

real	0m1.253s

user	0m0.907s

sys	0m0.143s



awk + sort:

real	0m3.696s

user	0m1.887s

sys	0m0.520s



awk + sort + uniq:

real	0m15.768s

user	0m12.233s

sys	0m0.820s



Plain dmenu:

awked into dmenu:

awk + sort + uniq into dmenu:

&lt;/pre&gt;&lt;p&gt;Run 2&lt;/p&gt;

&lt;pre&gt;

Plain awk &#39;{print $3}&#39;:

real	0m1.223s

user	0m0.923s

sys	0m0.107s



awk + sort:

real	0m2.799s

user	0m1.910s

sys	0m0.553s



awk + sort + uniq:

real	0m16.387s

user	0m12.019s

sys	0m0.787s

Plain dmenu:

awked into dmenu:

awk + sort + uniq into dmenu:

&lt;/pre&gt;&lt;p&gt;Not too bad.  It&#39;s especially uniq who seems to cause a lot of slowdown.  (in this dummy test file, are entries are unique. If there were lots of dupes, the results would probably be different, but I suspect that uniq always needs some time to do its work, dupes or not).  The real bottleneck seems to be raw cpu power.  Not storage bandwidth at all since Linux caches it.  If uncached, I estimate the sequential read would take 1.5 seconds or so. (about 30MB/s on common hard disks)&lt;/p&gt;

&lt;p&gt;Once the stuff gets piped into dmenu, there is a little lag but it&#39;s reasonably responsive imho.&lt;br /&gt;

Test performed on an athlon xp @ 2GHz.  1 GB of memory.  There were some other apps running, not a very professional benchmark but you get the idea :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tweaking Lighttpd stat() performance with fcgi-stat-accel</title>
      <link>http://localhost:1313/post/tweaking_lighttpd_stat_performance_with_fcgi-stat-accel/</link>
      <pubDate>Mon, 03 Mar 2008 21:12:42 -0400</pubDate>
      
      <guid>http://localhost:1313/post/tweaking_lighttpd_stat_performance_with_fcgi-stat-accel/</guid>
      <description>&lt;p&gt;If you serve lots of (small) files with Lighttpd you might notice you&#39;re not getting the throughput you would expect.  Other factors (such as latencies because of the random read patterns ) aside, a real show stopper is the stat() system call, which is a blocking system call ( no parallelism ).  Some clever guys thought of a way to solve this : a fastcgi program that does a stat(), so when it returns Lighty doesn&#39;t have to wait because the stat information will be in the Linux cache.  And in the meanwhile your Lighty thread can do other stuff.  

&lt;!--more--&gt;&lt;br/&gt;

(in Lighty 1.5 there will be a native way for asynchronous stat() calls but for 1.4 this hack works pretty damn well)&lt;/p&gt;

&lt;p&gt;This is explained on the &lt;a href=&#34;http://trac.lighttpd.net/trac/wiki/HowtoSpeedUpStatWithFastcgi&#34;&gt; HowtoSpeedUpStatWithFastcgi&lt;/a&gt; page on the &lt;a href=&#34;http://trac.lighttpd.net/trac/&#34;&gt; Lighty wiki&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now, for &lt;a href=&#34;http://www.netlog.com&#34;&gt;Netlog&lt;/a&gt; we needed to add some http headers ( Cache-Control: max-age, ETag, Expires and Last-Modified ) so we patched up the code a bit to do that, and a bit of other stuff.&lt;/p&gt;

&lt;p&gt;Ofcourse this is documented on &lt;a href=&#34;http://trac.lighttpd.net/trac/wiki/FcgiStatAccelWithMoreHttpHeaders&#34;&gt;the FcgiStatAccelWithMoreHttpHeaders page on the Lighty wiki&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Have fun !&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;/*&lt;/span&gt;

&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;  Originally written by Fobax.&lt;/span&gt;

&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;  Edited by darix to support controlling thread count at runtime. &lt;/span&gt;

&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;  Edited by poison and Dieter_be to support some http headers derived from the files.&lt;/span&gt;



&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;  Please do not remove any of the above.&lt;/span&gt;

&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;  &lt;/span&gt;

&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;  compile with: &lt;/span&gt;



&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;  $ gcc -lfcgi -lpthread fcgi-stat-accel.c -o fcgi-stat-accel&lt;/span&gt;



&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;  fcgi-stat-accel will use the PHP_FCGI_CHILDREN environment variable to set the thread count.&lt;/span&gt;



&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;  The default value, if spawned from lighttpd, is 20.&lt;/span&gt;

&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;*/&lt;/span&gt;



&lt;span style=&#34;color: #BC7A00&#34;&gt;#include &amp;quot;fcgi_config.h&amp;quot;&lt;/span&gt;



&lt;span style=&#34;color: #BC7A00&#34;&gt;#include &amp;lt;pthread.h&amp;gt;&lt;/span&gt;

&lt;span style=&#34;color: #BC7A00&#34;&gt;#include &amp;lt;sys/types.h&amp;gt;&lt;/span&gt;

&lt;span style=&#34;color: #BC7A00&#34;&gt;#include &amp;lt;unistd.h&amp;gt;   &lt;/span&gt;

&lt;span style=&#34;color: #BC7A00&#34;&gt;#include &amp;quot;fcgiapp.h&amp;quot;  &lt;/span&gt;

&lt;span style=&#34;color: #BC7A00&#34;&gt;#include &amp;lt;string.h&amp;gt;   &lt;/span&gt;

&lt;span style=&#34;color: #BC7A00&#34;&gt;#include &amp;lt;sys/types.h&amp;gt;&lt;/span&gt;

&lt;span style=&#34;color: #BC7A00&#34;&gt;#include &amp;lt;sys/stat.h&amp;gt; &lt;/span&gt;



&lt;span style=&#34;color: #BC7A00&#34;&gt;#include &amp;lt;stdlib.h&amp;gt;&lt;/span&gt;

&lt;span style=&#34;color: #BC7A00&#34;&gt;#include &amp;lt;stdio.h&amp;gt; &lt;/span&gt;



&lt;span style=&#34;color: #BC7A00&#34;&gt;#include &amp;quot;etag.h&amp;quot;&lt;/span&gt;

&lt;span style=&#34;color: #BC7A00&#34;&gt;#include &amp;quot;buffer.h&amp;quot;&lt;/span&gt;





&lt;span style=&#34;color: #BC7A00&#34;&gt;#define THREAD_COUNT 20&lt;/span&gt;





&lt;span style=&#34;color: #BC7A00&#34;&gt;#define FORBIDDEN(stream) \&lt;/span&gt;

        FCGX_FPrintF(stream, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;Status: 403 Forbidden&lt;/span&gt;&lt;span style=&#34;color: #BB6622; font-weight: bold&#34;&gt;\r\n&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;Content-Type: text/html&lt;/span&gt;&lt;span style=&#34;color: #BB6622; font-weight: bold&#34;&gt;\r\n\r\n&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;lt;h1&amp;gt;403 Forbidden&amp;lt;/h1&amp;gt;&lt;/span&gt;&lt;span style=&#34;color: #BB6622; font-weight: bold&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;&lt;/span&gt;);

&lt;span style=&#34;color: #BC7A00&#34;&gt;#define NOTFOUND(stream, filename) \&lt;/span&gt;

        FCGX_FPrintF(stream, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;Status: 404 Not Found&lt;/span&gt;&lt;span style=&#34;color: #BB6622; font-weight: bold&#34;&gt;\r\n&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;Content-Type: text/html&lt;/span&gt;&lt;span style=&#34;color: #BB6622; font-weight: bold&#34;&gt;\r\n\r\n&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;lt;h1&amp;gt;404 Not Found&amp;lt;/h1&amp;gt;&lt;/span&gt;&lt;span style=&#34;color: #BB6622; font-weight: bold&#34;&gt;\r\n&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;%s&amp;quot;&lt;/span&gt;, filename);

&lt;span style=&#34;color: #BC7A00&#34;&gt;#define SENDFILE(stream, filename, headers) \&lt;/span&gt;

        FCGX_FPrintF(stream, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;%sX-LIGHTTPD-send-file: %s&lt;/span&gt;&lt;span style=&#34;color: #BB6622; font-weight: bold&#34;&gt;\r\n\r\n&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;&lt;/span&gt;, headers, filename);



&lt;span style=&#34;color: #BC7A00&#34;&gt;#define EXPIRATION_TIME (int) 60*60*24*30&lt;/span&gt;





&lt;span style=&#34;color: #B00040&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #0000FF&#34;&gt;genheaders&lt;/span&gt; (&lt;span style=&#34;color: #B00040&#34;&gt;char&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt; mybuffer, &lt;span style=&#34;color: #B00040&#34;&gt;size_t&lt;/span&gt; bufferlen, &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color: #B00040&#34;&gt;char&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt; file)

{

        &lt;span style=&#34;color: #B00040&#34;&gt;char&lt;/span&gt; timebuf[&lt;span style=&#34;color: #666666&#34;&gt;32&lt;/span&gt;]; &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//possibly unsafe   &lt;/span&gt;

        &lt;span style=&#34;color: #B00040&#34;&gt;char&lt;/span&gt; lastmodbuf[&lt;span style=&#34;color: #666666&#34;&gt;32&lt;/span&gt;]; &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//possibly unsafe&lt;/span&gt;

        &lt;span style=&#34;color: #B00040&#34;&gt;char&lt;/span&gt; etag[&lt;span style=&#34;color: #666666&#34;&gt;128&lt;/span&gt;]; &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//possibly unsafe&lt;/span&gt;

        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;struct&lt;/span&gt; stat statbuf;

        &lt;span style=&#34;color: #B00040&#34;&gt;time_t&lt;/span&gt; exp;

        &lt;span style=&#34;color: #B00040&#34;&gt;time_t&lt;/span&gt; lastmod;  

        buffer &lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt;etag_raw;

        buffer &lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt;etag_ok ;

 

        &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//create buffers for Etag&lt;/span&gt;

        etag_raw &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; buffer_init();

        etag_ok &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; buffer_init();

                

        &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;// Stat the file&lt;/span&gt;

        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt; (stat (file, &lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;statbuf) &lt;span style=&#34;color: #666666&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;0&lt;/span&gt;)

        {

                &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;-1&lt;/span&gt;;

        }



        &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;// Clear the buffer&lt;/span&gt;

        memset (mybuffer, &lt;span style=&#34;color: #666666&#34;&gt;0&lt;/span&gt;, bufferlen);



        &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;// Get the local time&lt;/span&gt;

        exp &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; time (&lt;span style=&#34;color: #008000&#34;&gt;NULL&lt;/span&gt;) &lt;span style=&#34;color: #666666&#34;&gt;+&lt;/span&gt; EXPIRATION_TIME;

        lastmod &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; statbuf.st_mtime;



        strftime (timebuf, (&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;sizeof&lt;/span&gt; (timebuf) &lt;span style=&#34;color: #666666&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;sizeof&lt;/span&gt; (&lt;span style=&#34;color: #B00040&#34;&gt;char&lt;/span&gt;)) &lt;span style=&#34;color: #666666&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;%a, %d %b %Y %H:%M:%S GMT&amp;quot;&lt;/span&gt;, gmtime (&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;(exp)));

        strftime (lastmodbuf, (&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;sizeof&lt;/span&gt; (lastmodbuf) &lt;span style=&#34;color: #666666&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;sizeof&lt;/span&gt; (&lt;span style=&#34;color: #B00040&#34;&gt;char&lt;/span&gt;)) &lt;span style=&#34;color: #666666&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;%a, %d %b %Y %H:%M:%S GMT&amp;quot;&lt;/span&gt;, gmtime (&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;(lastmod)));



        etag_create(etag_raw, &lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;statbuf, ETAG_USE_SIZE);

        etag_mutate(etag_ok, etag_raw);



        buffer_free(etag_raw);



        snprintf (mybuffer, bufferlen, &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;Cache-Control: max-age=%d&lt;/span&gt;&lt;span style=&#34;color: #BB6622; font-weight: bold&#34;&gt;\r\n&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;ETag: \%s&lt;/span&gt;&lt;span style=&#34;color: #BB6622; font-weight: bold&#34;&gt;\r\n&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;Expires: %s&lt;/span&gt;&lt;span style=&#34;color: #BB6622; font-weight: bold&#34;&gt;\r\n&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;Last-Modified: %s&lt;/span&gt;&lt;span style=&#34;color: #BB6622; font-weight: bold&#34;&gt;\r\n&lt;/span&gt;&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;&lt;/span&gt;, EXPIRATION_TIME, etag_ok&lt;span style=&#34;color: #666666&#34;&gt;-&amp;gt;&lt;/span&gt;ptr, timebuf , lastmodbuf);



        buffer_free(etag_ok);



        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;0&lt;/span&gt;;

}

 

&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;static&lt;/span&gt; &lt;span style=&#34;color: #B00040&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color: #0000FF&#34;&gt;doit&lt;/span&gt;(&lt;span style=&#34;color: #B00040&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt;a){

        FCGX_Request request;

        &lt;span style=&#34;color: #B00040&#34;&gt;int&lt;/span&gt; rc;

        &lt;span style=&#34;color: #B00040&#34;&gt;char&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt;filename;

        &lt;span style=&#34;color: #B00040&#34;&gt;char&lt;/span&gt; extraheaders[&lt;span style=&#34;color: #666666&#34;&gt;192&lt;/span&gt;];

        &lt;span style=&#34;color: #B00040&#34;&gt;int&lt;/span&gt; r;



        FCGX_InitRequest(&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;request, &lt;span style=&#34;color: #666666&#34;&gt;0&lt;/span&gt;, FCGI_FAIL_ACCEPT_ON_INTR);



        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;while&lt;/span&gt;(&lt;span style=&#34;color: #666666&#34;&gt;1&lt;/span&gt;){

                &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//Some platforms require accept() serialization, some don&amp;#39;t. The documentation claims it to be thread safe&lt;/span&gt;

&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//              static pthread_mutex_t accept_mutex = PTHREAD_MUTEX_INITIALIZER;&lt;/span&gt;

&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//              pthread_mutex_lock(&amp;amp;accept_mutex);&lt;/span&gt;

                rc &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; FCGX_Accept_r(&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;request);

&lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//              pthread_mutex_unlock(&amp;amp;accept_mutex);&lt;/span&gt;



                &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt;(rc &lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;0&lt;/span&gt;)

                        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;break&lt;/span&gt;;



        &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//get the filename&lt;/span&gt;

                &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt;((filename &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; FCGX_GetParam(&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;SCRIPT_FILENAME&amp;quot;&lt;/span&gt;, request.envp)) &lt;span style=&#34;color: #666666&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color: #008000&#34;&gt;NULL&lt;/span&gt;){

                        FORBIDDEN(request.out);

        &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//don&amp;#39;t try to open directories&lt;/span&gt;

                }&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt;(filename[strlen(filename)&lt;span style=&#34;color: #666666&#34;&gt;-1&lt;/span&gt;] &lt;span style=&#34;color: #666666&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color: #BA2121&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;){

                        FORBIDDEN(request.out);

        &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//open the file&lt;/span&gt;

                }&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt;((r &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; genheaders (extraheaders, &lt;span style=&#34;color: #666666&#34;&gt;191&lt;/span&gt;, filename)) &lt;span style=&#34;color: #666666&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;0&lt;/span&gt;){

                        NOTFOUND(request.out, filename);

        &lt;span style=&#34;color: #408080; font-style: italic&#34;&gt;//no error, serve it&lt;/span&gt;

                }&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;else&lt;/span&gt;{

                        SENDFILE(request.out, filename, extraheaders);

                }



                FCGX_Finish_r(&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;request);

        }

        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color: #008000&#34;&gt;NULL&lt;/span&gt;;

}



&lt;span style=&#34;color: #B00040&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #0000FF&#34;&gt;main&lt;/span&gt;(&lt;span style=&#34;color: #B00040&#34;&gt;void&lt;/span&gt;){

        &lt;span style=&#34;color: #B00040&#34;&gt;int&lt;/span&gt; i,j,thread_count;

        &lt;span style=&#34;color: #B00040&#34;&gt;pthread_t&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt; id;

        &lt;span style=&#34;color: #B00040&#34;&gt;char&lt;/span&gt;&lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt; env_val;



        FCGX_Init();



        thread_count &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; THREAD_COUNT;

        env_val &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; getenv(&lt;span style=&#34;color: #BA2121&#34;&gt;&amp;quot;PHP_FCGI_CHILDREN&amp;quot;&lt;/span&gt;);

        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt; (env_val &lt;span style=&#34;color: #666666&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color: #008000&#34;&gt;NULL&lt;/span&gt;) {

                j &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; atoi(env_val);

                &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;if&lt;/span&gt; (j &lt;span style=&#34;color: #666666&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;0&lt;/span&gt;) {

                        thread_count &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; j;

                };

        };



        id &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; malloc(&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt;id) &lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt; thread_count);



        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; (i &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;0&lt;/span&gt;; i &lt;span style=&#34;color: #666666&#34;&gt;&amp;lt;&lt;/span&gt; thread_count; i&lt;span style=&#34;color: #666666&#34;&gt;++&lt;/span&gt;) {

                pthread_create(&lt;span style=&#34;color: #666666&#34;&gt;&amp;amp;&lt;/span&gt;id[i], &lt;span style=&#34;color: #008000&#34;&gt;NULL&lt;/span&gt;, doit, &lt;span style=&#34;color: #008000&#34;&gt;NULL&lt;/span&gt;);

        }



        doit(&lt;span style=&#34;color: #008000&#34;&gt;NULL&lt;/span&gt;);

        free(id);  

        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;0&lt;/span&gt;;  

}
&lt;/pre&gt;&lt;/div&gt;

</description>
    </item>
    
  </channel>
</rss>