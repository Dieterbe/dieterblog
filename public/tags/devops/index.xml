<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>devops on Dieter&#39;s blog</title>
    <link>http://localhost:1313/tags/devops/</link>
    <description>Recent content in devops on Dieter&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 10 Dec 2016 19:13:03 +0000</lastBuildDate><atom:link href="http://localhost:1313/tags/devops/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Practical fault detection: redux. Next-generation alerting now as presentation</title>
      <link>http://localhost:1313/posts/practical-fault-detection-redux-next-generation-alerting-now-as-presentation/</link>
      <pubDate>Sat, 10 Dec 2016 19:13:03 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/practical-fault-detection-redux-next-generation-alerting-now-as-presentation/</guid>
      
      <description>This summer I had the opportunity to present my practical fault detection concepts and hands-on approach as conference presentations.
First at Velocity and then at SRECon16 Europe. The latter page also contains the recorded video.
If you&amp;rsquo;re interested at all in tackling non-trivial timeseries alerting use cases (e.g. working with seasonal or trending data) this video should be useful to you.
It&amp;rsquo;s basically me trying to convey in a concrete way why I think the big-data and math-centered algorithmic approaches come with a variety of problems making them unrealistic and unfit, whereas the real breakthroughs happen when tools recognize the symbiotic relationship between operators and software, and focus on supporting a collaborative, iterative process to managing alerting over time.</description>
      
    </item>
    
    <item>
      <title>Focusing on open source monitoring.  Joining raintank.</title>
      <link>http://localhost:1313/posts/focusing-on-open-source-monitoring-joining-raintank/</link>
      <pubDate>Fri, 03 Jul 2015 09:22:02 -0700</pubDate>
      
      <guid>http://localhost:1313/posts/focusing-on-open-source-monitoring-joining-raintank/</guid>
      
      <description>Vimeo is special.  It changed my life.
But interests, goals and ambitions change.
This post is about leaving, joining raintank, working remote while traveling, open source monitoring, startups, personal relations, litmus and Grafana alerting</description>
      
    </item>
    
    <item>
      <title>Practical fault detection on timeseries part 2: first macros and templates</title>
      <link>http://localhost:1313/posts/practical-fault-detection-on-timeseries-part-2/</link>
      <pubDate>Mon, 27 Apr 2015 09:05:02 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/practical-fault-detection-on-timeseries-part-2/</guid>
      
      <description>In the &lt;a href=&#34;http://localhost:1313/practical-fault-detection-alerting-dont-need-to-be-data-scientist.html&#34;&gt;previous fault detection article&lt;/a&gt;, we saw how we can cover a lot of ground in fault detection with simple methods and technology that is available today.
It had an example of a simple but effective approach to find sudden spikes (peaks and drops) within fluctuating time series.
This post explains the continuation of that work and provides you the means to implement this yourself with minimal effort.
I&#39;m sharing with you:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://bosun.org&#34;&gt;Bosun&lt;/a&gt; macros which detect our most common not-trivially-detectable symptoms of problems&lt;/li&gt;
&lt;li&gt;Bosun notification template which provides a decent amount of information&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.grafana.org&#34;&gt;Grafana&lt;/a&gt; and &lt;a href=&#34;http://vimeo.github.io/graph-explorer/&#34;&gt;Graph-Explorer&lt;/a&gt; dashboards and integration for further troubleshooting&lt;/li&gt;
&lt;/ul&gt;
We reuse this stuff for a variety of cases where the data behaves similarly and I suspect that you will be able to apply this to a bunch of your monitoring targets as well.
</description>
      
    </item>
    
    <item>
      <title>Practical fault detection &amp; alerting.  You don&#39;t need to be a data scientist</title>
      <link>http://localhost:1313/posts/practical-fault-detection-alerting-dont-need-to-be-data-scientist/</link>
      <pubDate>Thu, 29 Jan 2015 09:08:02 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/practical-fault-detection-alerting-dont-need-to-be-data-scientist/</guid>
      
      <description>&lt;br/&gt;
As we try to retain visibility into our increasingly complicated applications and infrastructure, we&#39;re building out more advanced monitoring systems.
Specifically, a lot of work is being done on alerting via fault and anomaly detection.
This post covers some common notions around these new approaches, debunks some of the myths that ask for over-complicated solutions, and provides some practical pointers that any programmer or sysadmin can implement that don&#39;t require becoming a data scientist.
</description>
      
    </item>
    
    <item>
      <title>IT-Telemetry Google group.  Trying to foster more collaboration around operational insights.</title>
      <link>http://localhost:1313/posts/it-telemetry-google-group-collaboration-operational-insights/</link>
      <pubDate>Sat, 06 Dec 2014 16:01:02 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/it-telemetry-google-group-collaboration-operational-insights/</guid>
      
      <description>The discipline of collecting infrastructure &amp; application performance metrics, aggregation, storage, visualizations and alerting has many terms associated with it... Telemetry. Insights engineering. Operational visibility. I&#39;ve seen a bunch of people present their work in advancing the state of the art in this domain: from Anton Lebedevich&#39;s statistics for monitoring series, Toufic Boubez&#39; talks on anomaly detection and Twitter&#39;s work on detecting mean shifts to projects such as flapjack (which aims to offload the alerting responsibility from your monitoring apps), the metrics 2.</description>
      
    </item>
    
    <item>
      <title>A real whisper-to-InfluxDB program.</title>
      <link>http://localhost:1313/posts/a-real-whisper-to-influxdb-program/</link>
      <pubDate>Tue, 30 Sep 2014 08:37:48 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/a-real-whisper-to-influxdb-program/</guid>
      
      <description>The whisper-to-influxdb migration script I posted earlier is pretty bad. A shell script, without concurrency, and an undiagnosed performance issue. I hinted that one could write a Go program using the unofficial whisper-go bindings and the influxdb Go client library. That&#39;s what I did now, it&#39;s at github.com/vimeo/whisper-to-influxdb. It uses configurable amounts of workers for both whisper fetches and InfluxDB commits, but it&#39;s still a bit naive in the sense that it commits to InfluxDB one serie at a time, irrespective of how many records are in it.</description>
      
    </item>
    
    <item>
      <title>InfluxDB as a graphite backend, part 2</title>
      <link>http://localhost:1313/posts/influxdb-as-graphite-backend-part2/</link>
      <pubDate>Wed, 24 Sep 2014 07:56:01 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/influxdb-as-graphite-backend-part2/</guid>
      
      <description>&lt;br&gt;
&lt;br/&gt;Updated oct 1, 2014 with a new &lt;i&gt;Disk space efficiency&lt;/i&gt; section which fixes some mistakes and adds more clarity.
&lt;br/&gt;

&lt;p&gt;
The &lt;i&gt;Graphite + InfluxDB&lt;/i&gt; series continues.
&lt;ul&gt;
&lt;li&gt;In part 1, &lt;a href=&#34;http://localhost:1313/on-graphite-whisper-and-influxdb.html&#34;&gt;&#34;On Graphite, Whisper and InfluxDB&#34;&lt;/a&gt; I described the problems of Graphite&#39;s whisper and ceres, why I disagree with common graphite clustering advice as being the right path forward, what a great timeseries storage system would mean to me, why InfluxDB - despite being the youngest project - is my main interest right now, and introduced my approach for combining both and leveraging their respective strengths: InfluxDB as an ingestion and storage backend (and at some point, realtime processing and pub-sub) and graphite for its renown data processing-on-retrieval functionality.
Furthermore, I introduced some tooling: &lt;a href=&#34;https://github.com/graphite-ng/carbon-relay-ng&#34;&gt;carbon-relay-ng&lt;/a&gt; to easily route streams of carbon data (metrics datapoints) to storage backends, allowing me to send production data to Carbon+whisper as well as InfluxDB in parallel, &lt;a href=&#34;https://github.com/brutasse/graphite-api&#34;&gt;graphite-api&lt;/a&gt;, the simpler Graphite API server, with &lt;a href=&#34;https://github.com/vimeo/graphite-influxdb&#34;&gt;graphite-influxdb&lt;/a&gt; to fetch data from InfluxDB.
&lt;/li&gt;
&lt;li&gt;Not Graphite related, but I wrote &lt;a href=&#34;https://github.com/Dieterbe/influx-cli&#34;&gt;influx-cli&lt;/a&gt; which I introduced &lt;a href=&#34;http://localhost:1313/influx-cli_a_commandline_interface_to_influxdb.html&#34;&gt;here&lt;/a&gt;.  It allows to easily interface with InfluxDB and measure the duration of operations, which will become useful for this article.&lt;/li&gt;
&lt;li&gt;In the &lt;a href=&#34;graphite-influxdb-intermezzo-migrating-old-data-and-a-more-powerful-carbon-relay.html&#34;&gt;Graphite &amp;amp; Influxdb intermezzo&lt;/a&gt; I shared a script to import whisper data into InfluxDB and noted some write performance issues I was seeing, but the better part of the article described the various improvements done to &lt;a href=&#34;https://github.com/graphite-ng/carbon-relay-ng&#34;&gt;carbon-relay-ng&lt;/a&gt;, which is becoming an increasingly versatile and useful tool.&lt;/li&gt;
&lt;li&gt;In &lt;a href=&#34;http://localhost:1313/using-influxdb-as-graphite-backend-part2.html&#34;&gt;part 2&lt;/a&gt;, which you are reading now, I&#39;m going to describe recent progress, share more info about my setup, testing results, state of affairs, and ideas for future work&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Graphite &amp; Influxdb intermezzo: migrating old data and a more powerful carbon relay</title>
      <link>http://localhost:1313/posts/graphite-influxdb-intermezzo-migrating-old-data-and-a-more-powerful-carbon-relay/</link>
      <pubDate>Sat, 20 Sep 2014 15:18:32 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/graphite-influxdb-intermezzo-migrating-old-data-and-a-more-powerful-carbon-relay/</guid>
      
      <description>Migrating data from whisper into InfluxDB &#34;How do i migrate whisper data to influxdb&#34; is a question that comes up regularly, and I&#39;ve always replied it should be easy to write a tool to do this. I personally had no need for this, until a recent small influxdb outage where I wanted to sync data from our backup server (running graphite + whisper) to influxdb, so I wrote a script: #!</description>
      
    </item>
    
    <item>
      <title>Monitorama PDX &amp; my metrics 2.0 presentation</title>
      <link>http://localhost:1313/posts/monitorama-pdx-metrics20/</link>
      <pubDate>Thu, 29 May 2014 10:39:32 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/monitorama-pdx-metrics20/</guid>
      
      <description>Earlier this month we had another iteration of the Monitorama conference, this time in Portland, Oregon. (photo by obfuscurity) I think the conference was better than the first one in Boston, much more to learn. Also this one was quite focused on telemetry (timeseries metrics processing), lots of talks on timeseries analytics, not so much about things like sensu or nagios. Adrian Cockroft&#39;s keynote brought some interesting ideas to the table, like building a feedback loop into the telemetry to drive infrastructure changes (something we do at Vimeo, I briefly give an example in the intro of my talk) or shortening the time from fault to alert (which I&#39;m excited to start working on soon) My other favorite was Noah Kantrowitz&#39;s talk about applying audio DSP techniques to timeseries, I always loved audio processing and production.</description>
      
    </item>
    
    <item>
      <title>On Graphite, Whisper and InfluxDB</title>
      <link>http://localhost:1313/posts/on-graphite-whisper-and-influxdb/</link>
      <pubDate>Sun, 18 May 2014 13:22:32 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/on-graphite-whisper-and-influxdb/</guid>
      
      <description>&lt;h4&gt;Graphite, and the storage Achilles heel&lt;/h4&gt;

Graphite is a neat timeseries metrics storage system that comes with a powerful querying api, mainly due to the whole bunch of &lt;a href=&#34;http://graphite.readthedocs.org/en/latest/functions.html&#34;&gt;available processing functions&lt;/a&gt;.
&lt;br/&gt;For medium to large setups, the storage aspect quickly becomes a pain point.  Whisper, the default graphite storage format, is a simple storage format, using one file per metric (timeseries).
</description>
      
    </item>
    
    <item>
      <title>Metrics 2.0 now has its own website!</title>
      <link>http://localhost:1313/posts/metrics-2-0-own-website/</link>
      <pubDate>Wed, 23 Apr 2014 09:10:32 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/metrics-2-0-own-website/</guid>
      
      <description>Metrics 2.0 started as a &lt;a href=&#34;http://dieter.plaetinck.be/metrics_2_a_proposal.html&#34;&gt;half-formal proposal&lt;/a&gt; and an implementation via &lt;a href=&#34;http://vimeo.github.io/graph-explorer/&#34;&gt;graph-explorer&lt;/a&gt;, but is broad enough in scope that it deserves its own website, its own spec, its own community.  That&#39;s why I launched &lt;a href=&#34;http://metrics20.org/&#34;&gt;metrics20.org&lt;/a&gt; and a &lt;a href=&#34;https://groups.google.com/forum/#!forum/metrics20&#34;&gt;discussion group&lt;/a&gt;.
</description>
      
    </item>
    
    <item>
      <title>Introduction talk to metrics 2.0 and Graph-Explorer</title>
      <link>http://localhost:1313/posts/introduction_talk_to_metrics2-0_and_graph_explorer/</link>
      <pubDate>Sun, 23 Feb 2014 16:20:32 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/introduction_talk_to_metrics2-0_and_graph_explorer/</guid>
      
      <description>This week I had the opportunity to present &lt;a href=&#34;http://dieter.plaetinck.be/metrics_2_a_proposal.html&#34;&gt;metrics 2.0&lt;/a&gt; and
&lt;a href=&#34;http://vimeo.github.io/graph-explorer/&#34;&gt;Graph-Explorer&lt;/a&gt; at the
&lt;a href=&#34;http://www.meetup.com/Full-Stack-Engineering-Meetup/&#34;&gt;Full-stack engineering meetup&lt;/a&gt;.
</description>
      
    </item>
    
    <item>
      <title>Metrics 2.0: a proposal</title>
      <link>http://localhost:1313/posts/metrics_2_a_proposal/</link>
      <pubDate>Sat, 14 Sep 2013 11:29:32 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/metrics_2_a_proposal/</guid>
      
      <description>&lt;p&gt;
&lt;ul&gt;
&lt;li&gt;
Graphite&#39;s metrics are strings comprised of dot-separated nodes which, due to their ordering, can be represented as a tree.
Many other places use a similar format (stats in /proc etc).
&lt;/li&gt;
&lt;li&gt;
OpenTSDB&#39;s metrics are shorter, because they move some of the dimensions (server, etc) into key-value tags.
&lt;/li&gt;
&lt;/ul&gt;
&lt;b&gt;I think we can do better...&lt;/b&gt;
&lt;br/&gt;
I think our metrics format is restrictive and we do our self a disservice using it:
</description>
      
    </item>
    
    <item>
      <title>Graphite-ng: A next-gen graphite server in Go.</title>
      <link>http://localhost:1313/posts/graphite-ng_a-next-gen-graphite-server-in-go/</link>
      <pubDate>Sat, 07 Sep 2013 20:54:20 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/graphite-ng_a-next-gen-graphite-server-in-go/</guid>
      
      <description>&lt;p&gt;
I&#39;ve been a &lt;a href=&#34;https://github.com/graphite-project/&#34;&gt;graphite&lt;/a&gt; contributor for a while (and still am).  It&#39;s a &lt;i&gt;great&lt;/i&gt; tool for timeseries metrics.
Two weeks ago I started working on &lt;a href=&#34;https://github.com/graphite-ng/graphite-ng&#34;&gt;Graphite-ng&lt;/a&gt;:
it&#39;s somewhere between an early clone/rewrite, a redesign, and an experiment playground, written in &lt;a href=&#34;http://golang.org&#34;&gt;Golang&lt;/a&gt;.
The focus of my work so far is the API web server, which is a functioning prototype, it answers requests like&lt;/p&gt;
{{&lt; highlight &#34;javascript&#34; &#34;style=default&#34; &gt;}}
/render/?target=sum(scale(stats.web2,5.12),derivative(stats.web2))
{{&lt; /highlight &gt;}}
&lt;p&gt;
I.e. it lets you retrieve your timeseries, processed by function pipelines which are setup on the fly based on a spec in your http/rest arguments.
Currently it only fetches metrics from text files but I&#39;m working on decent metrics storage as well.
&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>A few common graphite problems and how they are already solved.</title>
      <link>http://localhost:1313/posts/a_few_common_graphite_problems_and_how_they_are_already_solved/</link>
      <pubDate>Thu, 04 Apr 2013 08:54:20 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/a_few_common_graphite_problems_and_how_they_are_already_solved/</guid>
      
      <description></description>
      
    </item>
    
    <item>
      <title>Hi Planet Devops and Infratalk</title>
      <link>http://localhost:1313/posts/hi_planet_devops_and_infratalk/</link>
      <pubDate>Sun, 24 Mar 2013 11:36:20 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/hi_planet_devops_and_infratalk/</guid>
      
      <description>This &lt;a href=&#34;http://dieter.plaetinck.be&#34;&gt;blog&lt;/a&gt; just got added to &lt;a href=&#34;http://www.planetdevops.net/&#34;&gt;planet devops&lt;/a&gt; and &lt;a href=&#34;http://infra-talk.org/&#34;&gt;infra-talk&lt;/a&gt;,
so for my new readers: you might know me as Dieterbe on irc, &lt;a href=&#34;https://github.com/Dieterbe&#34;&gt;github&lt;/a&gt; or &lt;a href=&#34;https://twitter.com/Dieter_be&#34;&gt;twitter&lt;/a&gt;.
Since my &lt;a href=&#34;http://localhost:1313/moving-to-nyc.html&#34;&gt;move from Belgium to NYC&lt;/a&gt; (to do backend stuff at Vimeo) I&#39;ve started writing more about devops-y topics
(whereas I used to write more about general hacking and
&lt;a href=&#34;http://localhost:1313/tag/arch&#34;&gt;arch linux release engineering and (automated) installations&lt;/a&gt;).
I&#39;ll mention some earlier posts you might be interested in:
</description>
      
    </item>
    
    <item>
      <title>Profiling and behavior testing of processes and daemons, and Devopsdays NYC</title>
      <link>http://localhost:1313/posts/profiling_and_behavior_testing_processes_daemons_devopsdays_nyc/</link>
      <pubDate>Mon, 21 Jan 2013 15:25:14 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/profiling_and_behavior_testing_processes_daemons_devopsdays_nyc/</guid>
      
      <description>&lt;h3&gt;Profiling a process run&lt;/h3&gt;
&lt;a href=&#34;https://github.com/Dieterbe/profile-process&#34;&gt;
&lt;img style=&#34;float:left;margin:0 5px 0 0;&#34; src=&#34;http://localhost:1313/files/presentation-simple-black-box/images/profile_io.png&#34; width=&#34;100px&#34; height=&#34;100px&#34;/&gt;
&lt;/a&gt;
I wanted the ability to run a given process and get
&lt;br/&gt;a plot of key metrics (cpu usage, memory usage, disk i/o) throughout the duration of the process run.
&lt;br/&gt;Something light-weight with minimal dependencies so I can easily install it on a server for a one-time need.
&lt;br/&gt;Couldn&#39;t find a tool for it, so I wrote &lt;a href=&#34;https://github.com/Dieterbe/profile-process&#34;&gt;profile-process&lt;/a&gt;
&lt;br/&gt;which does exactly that in &lt;100 lines of python.
&lt;br/&gt;
&lt;br/&gt;

&lt;h3&gt;black-box behavior testing processes/daemons&lt;/h3&gt;
&lt;a href=&#34;https://github.com/vimeo/simple-black-box&#34;&gt;
&lt;img style=&#34;float:left;margin:0 5px 0 0;&#34; src=&#34;http://localhost:1313/files/presentation-simple-black-box/images/screenshot-no-pause.png&#34; width=&#34;150px&#34; height=&#34;100px&#34;/&gt;
&lt;/a&gt;
I wrote &lt;a href=&#34;https://github.com/vimeo/simple-black-box&#34;&gt;simple-black-box&lt;/a&gt; to do this.
&lt;br/&gt;It runs the subject(s) in a crafted sandbox, sends input (http requests, commands, ...)
&lt;br/&gt;and allows to make assertions on http/statsd requests/responses, network listening state, processes running, log entries,
&lt;br/&gt;file existence/checksums in the VFS/swift clusters, etc.
&lt;br/&gt;Each test-case is a scenario.
&lt;br/&gt;It also can use &lt;a href=&#34;http://logstash.net/&#34;&gt;logstash&lt;/a&gt; to give a centralized &#34;distributed stack trace&#34; when you need to debug a failure after
multiple processes interacting and acting upon received messages; or to compare behavior across different scenario runs.
&lt;br/&gt;You can integrate this with profile-process to compare runtime behaviors across testcases/scenarios.
</description>
      
    </item>
    
    <item>
      <title>Graph-Explorer: A graphite dashboard unlike any other</title>
      <link>http://localhost:1313/posts/graph-explorer-a-graphite-dashboard-unlike-any-other/</link>
      <pubDate>Wed, 09 Jan 2013 09:25:36 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/graph-explorer-a-graphite-dashboard-unlike-any-other/</guid>
      
      <description>The above sounds like a marketing phrase and I&#39;m just as skeptical of them as you, but I feel it&#39;s in place. Not because GE is necessarily better, but it&#39;s certainly &lt;i&gt;different&lt;/i&gt;.
</description>
      
    </item>
    
    <item>
      <title>Client-side rendered graphite charts for all</title>
      <link>http://localhost:1313/posts/client-side-rendered-graphite-charts-for-all/</link>
      <pubDate>Wed, 14 Nov 2012 08:49:56 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/client-side-rendered-graphite-charts-for-all/</guid>
      
      <description>Client-side rendering of charts as opposed to using graphite&#39;s server side generated png&#39;s
allows various interactivity features, such as:
</description>
      
    </item>
    
    <item>
      <title>Anthracite, an event database to enrich monitoring dashboards and to allow visual and numerical analysis of events that have a business impact</title>
      <link>http://localhost:1313/posts/anthracite-event-database-enrich-monitoring-dashboards-visual-numerical-analysis-events-business-impact/</link>
      <pubDate>Mon, 12 Nov 2012 08:49:56 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/anthracite-event-database-enrich-monitoring-dashboards-visual-numerical-analysis-events-business-impact/</guid>
      
      <description>&lt;h4&gt;Introduction&lt;/h4&gt;
&lt;p&gt;Graphite can show events such as &lt;a href=&#34;http://codeascraft.etsy.com/2010/12/08/track-every-release/&#34;&gt;code deploys&lt;/a&gt; and
&lt;a href=&#34;https://github.com/joemiller/puppet-graphite_event&#34;&gt;puppet changes&lt;/a&gt; as vertical markers on your graph.
With the advent of new graphite dashboards and interfaces where we can have popups and annotations to show metadata for each event (by means of client-side rendering),
it&#39;s time we have a database to track all events along with categorisation and text descriptions (which can include rich text and hyperlinks).
Graphite is meant for time series (metrics over time), Anthracite aims to be the companion for annotated events.&lt;br&gt;
More precisely, &lt;strong&gt;Anthracite aims to be a database of &#34;relevant events&#34;&lt;/strong&gt; (see further down), &lt;strong&gt;for the purpose of enriching monitoring dashboards,
as well as allowing visual and numerical analysis of events that have a business impact&lt;/strong&gt; (for the latter, see &#34;&lt;i&gt;Thoughts on incident nomenclature, severity levels and incident analysis&lt;/i&gt;&#34; below)&lt;br&gt;
It has a TCP receiver, a database (sqlite3), a http interface to deliver event data in many formats and a simple web frontend for humans.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Histograms in statsd, and graphing them over time with graphite.</title>
      <link>http://localhost:1313/posts/histogram-statsd-graphing-over-time-with-graphite/</link>
      <pubDate>Wed, 07 Nov 2012 18:45:11 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/histogram-statsd-graphing-over-time-with-graphite/</guid>
      
      <description>&lt;p&gt;
I submitted a pull request to statsd which adds &lt;a href=&#34;https://github.com/etsy/statsd/pull/162&#34;&gt;histogram support&lt;/a&gt;.
&lt;img style=&#34;float:left;margin:0 5px 0 0;&#34; src=&#34;http://localhost:1313/files/Black_cherry_tree_histogram.svg.png&#34; alt=&#34;Example histogram, from Wikipedia&#34;/&gt;
&lt;br/&gt;(refresher: a histogram is [a visualization of] a frequency distribution of data,
paraphrasing your data by keeping frequencies for entire classes (ranges of data).
&lt;a href=&#34;http://en.wikipedia.org/wiki/Histogram&#34;&gt;histograms - Wikipedia&lt;/a&gt;)
&lt;br/&gt;It&#39;s commonly documented how to plot single histograms, that is a 2D diagram consisting of rectangles whose
&lt;ul&gt;
&lt;li&gt;area is proportional to the frequency of a variable&lt;/li&gt;
&lt;li&gt;whose width is equal to the class interval&lt;/li&gt;
&lt;/ul&gt;
Class intervals go on x-axis, frequencies on y-axis.
&lt;br/&gt;
&lt;br/&gt;
Note: histogram class intervals are supposed to have the same width.
&lt;br/&gt;My implementation allows arbitrary class intervals with potentially different widths,
as well as an upper boundary of infinite.
&lt;/p&gt;
&lt;h4&gt;Plotting histograms.. over time&lt;/h4&gt;
</description>
      
    </item>
    
    <item>
      <title>Dell crowbar openstack swift</title>
      <link>http://localhost:1313/posts/dell_crowbar_openstack_swift/</link>
      <pubDate>Wed, 02 May 2012 11:50:11 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/dell_crowbar_openstack_swift/</guid>
      
      <description>Learned about &lt;a href=&#34;https://github.com/dellcloudedge/crowbar&#34;&gt;Dell Crowbar&lt;/a&gt; the other day.  It seems to be (becoming) a tool I&#39;ve wanted for quite a while, because it takes automating physical infrastructure to a new level, and is also convenient on virtual.
</description>
      
    </item>
    
    <item>
      <title>What the open source community can learn from Devops</title>
      <link>http://localhost:1313/posts/what_the_open_source_community_can_learn_from_devops/</link>
      <pubDate>Fri, 03 Sep 2010 22:26:22 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/what_the_open_source_community_can_learn_from_devops/</guid>
      
      <description>&lt;p&gt;Being active as both a developer and ops person in the professional life, and both an open source developer and packager in my spare time, I noticed some common ground between both worlds, and I think the open source community can learn from the Devops movement which is solving problems in the professional tech world.&lt;/p&gt;
&lt;p&gt;For the sake of getting a point across, I&#39;ll simplify some things.&lt;/p&gt;
&lt;h3&gt;First, a crash course on Devops...&lt;/h3&gt;
&lt;p&gt;</description>
      
    </item>
    
    <item>
      <title>RRDtool: updating RRA settings and keeping your collected data</title>
      <link>http://localhost:1313/posts/rrdtool_updating_rra_settings_and_keeping_your_collected_data/</link>
      <pubDate>Wed, 09 Dec 2009 15:05:14 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/rrdtool_updating_rra_settings_and_keeping_your_collected_data/</guid>
      
      <description>When you use &lt;a href=&#34;http://oss.oetiker.ch/rrdtool/&#34;&gt;rrdtool&lt;/a&gt;, it can happen that you first create your databases, then collect a whole bunch of data and decide later you want more accuracy/longer periods.&lt;br /&gt;
</description>
      
    </item>
    
  </channel>
</rss>
