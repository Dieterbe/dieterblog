<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>perf on Dieter&#39;s blog</title>
    <link>http://localhost:1313/tags/perf/</link>
    <description>Recent content in perf on Dieter&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 18 May 2014 13:22:32 -0400</lastBuildDate><atom:link href="http://localhost:1313/tags/perf/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>On Graphite, Whisper and InfluxDB</title>
      <link>http://localhost:1313/posts/on-graphite-whisper-and-influxdb/</link>
      <pubDate>Sun, 18 May 2014 13:22:32 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/on-graphite-whisper-and-influxdb/</guid>
      
      <description>&lt;h4&gt;Graphite, and the storage Achilles heel&lt;/h4&gt;

Graphite is a neat timeseries metrics storage system that comes with a powerful querying api, mainly due to the whole bunch of &lt;a href=&#34;http://graphite.readthedocs.org/en/latest/functions.html&#34;&gt;available processing functions&lt;/a&gt;.
&lt;br/&gt;For medium to large setups, the storage aspect quickly becomes a pain point.  Whisper, the default graphite storage format, is a simple storage format, using one file per metric (timeseries).
</description>
      
    </item>
    
    <item>
      <title>Graphite-ng: A next-gen graphite server in Go.</title>
      <link>http://localhost:1313/posts/graphite-ng_a-next-gen-graphite-server-in-go/</link>
      <pubDate>Sat, 07 Sep 2013 20:54:20 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/graphite-ng_a-next-gen-graphite-server-in-go/</guid>
      
      <description>&lt;p&gt;
I&#39;ve been a &lt;a href=&#34;https://github.com/graphite-project/&#34;&gt;graphite&lt;/a&gt; contributor for a while (and still am).  It&#39;s a &lt;i&gt;great&lt;/i&gt; tool for timeseries metrics.
Two weeks ago I started working on &lt;a href=&#34;https://github.com/graphite-ng/graphite-ng&#34;&gt;Graphite-ng&lt;/a&gt;:
it&#39;s somewhere between an early clone/rewrite, a redesign, and an experiment playground, written in &lt;a href=&#34;http://golang.org&#34;&gt;Golang&lt;/a&gt;.
The focus of my work so far is the API web server, which is a functioning prototype, it answers requests like&lt;/p&gt;
{{&lt; highlight &#34;javascript&#34; &#34;style=default&#34; &gt;}}
/render/?target=sum(scale(stats.web2,5.12),derivative(stats.web2))
{{&lt; /highlight &gt;}}
&lt;p&gt;
I.e. it lets you retrieve your timeseries, processed by function pipelines which are setup on the fly based on a spec in your http/rest arguments.
Currently it only fetches metrics from text files but I&#39;m working on decent metrics storage as well.
&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Profiling and behavior testing of processes and daemons, and Devopsdays NYC</title>
      <link>http://localhost:1313/posts/profiling_and_behavior_testing_processes_daemons_devopsdays_nyc/</link>
      <pubDate>Mon, 21 Jan 2013 15:25:14 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/profiling_and_behavior_testing_processes_daemons_devopsdays_nyc/</guid>
      
      <description>&lt;h3&gt;Profiling a process run&lt;/h3&gt;
&lt;a href=&#34;https://github.com/Dieterbe/profile-process&#34;&gt;
&lt;img style=&#34;float:left;margin:0 5px 0 0;&#34; src=&#34;http://localhost:1313/files/presentation-simple-black-box/images/profile_io.png&#34; width=&#34;100px&#34; height=&#34;100px&#34;/&gt;
&lt;/a&gt;
I wanted the ability to run a given process and get
&lt;br/&gt;a plot of key metrics (cpu usage, memory usage, disk i/o) throughout the duration of the process run.
&lt;br/&gt;Something light-weight with minimal dependencies so I can easily install it on a server for a one-time need.
&lt;br/&gt;Couldn&#39;t find a tool for it, so I wrote &lt;a href=&#34;https://github.com/Dieterbe/profile-process&#34;&gt;profile-process&lt;/a&gt;
&lt;br/&gt;which does exactly that in &lt;100 lines of python.
&lt;br/&gt;
&lt;br/&gt;

&lt;h3&gt;black-box behavior testing processes/daemons&lt;/h3&gt;
&lt;a href=&#34;https://github.com/vimeo/simple-black-box&#34;&gt;
&lt;img style=&#34;float:left;margin:0 5px 0 0;&#34; src=&#34;http://localhost:1313/files/presentation-simple-black-box/images/screenshot-no-pause.png&#34; width=&#34;150px&#34; height=&#34;100px&#34;/&gt;
&lt;/a&gt;
I wrote &lt;a href=&#34;https://github.com/vimeo/simple-black-box&#34;&gt;simple-black-box&lt;/a&gt; to do this.
&lt;br/&gt;It runs the subject(s) in a crafted sandbox, sends input (http requests, commands, ...)
&lt;br/&gt;and allows to make assertions on http/statsd requests/responses, network listening state, processes running, log entries,
&lt;br/&gt;file existence/checksums in the VFS/swift clusters, etc.
&lt;br/&gt;Each test-case is a scenario.
&lt;br/&gt;It also can use &lt;a href=&#34;http://logstash.net/&#34;&gt;logstash&lt;/a&gt; to give a centralized &#34;distributed stack trace&#34; when you need to debug a failure after
multiple processes interacting and acting upon received messages; or to compare behavior across different scenario runs.
&lt;br/&gt;You can integrate this with profile-process to compare runtime behaviors across testcases/scenarios.
</description>
      
    </item>
    
    <item>
      <title>Histograms in statsd, and graphing them over time with graphite.</title>
      <link>http://localhost:1313/posts/histogram-statsd-graphing-over-time-with-graphite/</link>
      <pubDate>Wed, 07 Nov 2012 18:45:11 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/histogram-statsd-graphing-over-time-with-graphite/</guid>
      
      <description>&lt;p&gt;
I submitted a pull request to statsd which adds &lt;a href=&#34;https://github.com/etsy/statsd/pull/162&#34;&gt;histogram support&lt;/a&gt;.
&lt;img style=&#34;float:left;margin:0 5px 0 0;&#34; src=&#34;http://localhost:1313/files/Black_cherry_tree_histogram.svg.png&#34; alt=&#34;Example histogram, from Wikipedia&#34;/&gt;
&lt;br/&gt;(refresher: a histogram is [a visualization of] a frequency distribution of data,
paraphrasing your data by keeping frequencies for entire classes (ranges of data).
&lt;a href=&#34;http://en.wikipedia.org/wiki/Histogram&#34;&gt;histograms - Wikipedia&lt;/a&gt;)
&lt;br/&gt;It&#39;s commonly documented how to plot single histograms, that is a 2D diagram consisting of rectangles whose
&lt;ul&gt;
&lt;li&gt;area is proportional to the frequency of a variable&lt;/li&gt;
&lt;li&gt;whose width is equal to the class interval&lt;/li&gt;
&lt;/ul&gt;
Class intervals go on x-axis, frequencies on y-axis.
&lt;br/&gt;
&lt;br/&gt;
Note: histogram class intervals are supposed to have the same width.
&lt;br/&gt;My implementation allows arbitrary class intervals with potentially different widths,
as well as an upper boundary of infinite.
&lt;/p&gt;
&lt;h4&gt;Plotting histograms.. over time&lt;/h4&gt;
</description>
      
    </item>
    
    <item>
      <title>Poor mans pickle implementations benchmark</title>
      <link>http://localhost:1313/posts/poor_mans_pickle_implementations_benchmark/</link>
      <pubDate>Thu, 16 Jun 2011 22:32:12 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/poor_mans_pickle_implementations_benchmark/</guid>
      
      <description></description>
      
    </item>
    
    <item>
      <title>Rsyncbench, an rsync benchmarking tool</title>
      <link>http://localhost:1313/posts/rsyncbench_an_rsync_benchmarking_tool/</link>
      <pubDate>Fri, 15 Oct 2010 09:38:12 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/rsyncbench_an_rsync_benchmarking_tool/</guid>
      
      <description>&lt;p&gt;Background info:&lt;br /&gt;
I&#39;m currently in the process of evaluating (V)PS hosting providers and backup solutions.  The idea being: I want a (V)PS to run my stuff, which doesn&#39;t need much disk space,&lt;br /&gt;
but in the meantime it might be a good idea to look for online backup solutions (oops did I say &#34;online&#34;? I meant &#34;cloud&#34;), like on the (V)PS itself, or maybe as a separate solution.&lt;br /&gt;
But I&#39;ve got some diverse amount of data (my personal data is mostly a lot of small plaintext files, my mom has a windows VM for which I considered syncing the entire vdi file)&lt;br /&gt;
At this point the biggest contenders are &lt;a href=&#34;http://linode.com/&#34;&gt;Linode&lt;/a&gt; (which offers quite some flexibility and management tools, but becomes expensive when you want extra disk space (2$/month*GB), &lt;a href=&#34;http://www.rackspace.com/apps/backup_and_collaboration/data_backup_software/&#34;&gt;Rackspace backup&lt;/a&gt; gives you 10GB for 5$/month, but they have nice backup tools so I could only backup the important files from within the windows VM (~200MB), and then there&#39;s &lt;a href=&#34;http://www.hetzner.de/&#34;&gt;Hetzner&lt;/a&gt;, which offers powerful physical private servers with a lot of storage (160GB) for 29eur/month, but less flexibility (I.e. kvm-over-ip costs an extra 15eur/month)&lt;/p&gt;
&lt;p&gt;Another issue, given the limited capacity of Belgian internet connections, I needed to figure out how much bandwith rsync really needs, so I can calculate if the duration of a backup run including syncing the full vdi file is still reasonable.&lt;/p&gt;
&lt;p&gt;I couldn&#39;t find an rsync benchmarking tool, so I wrote my own.&lt;/p&gt;
&lt;p&gt;Features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;simple&lt;/li&gt;
&lt;li&gt;non invasive: you specify the target and destination hosts (just localhost is fine too), and file locations&lt;/li&gt;
&lt;li&gt;measures time spent, bytes sent (measured with tcpdump), and data sent (rsync&#39;s statistics which takes compression into account)&lt;/li&gt;
&lt;li&gt;supports plugins&lt;/li&gt;
&lt;li&gt;generates png graphs using Gnuplot&lt;/li&gt;
&lt;li&gt;two current plugins: one using files of various sizes, both randomly generated (/dev/urandom) and easily compressable (/dev/zero), does some use cases like initial sync, second sync (no-op), and syncing with a data block appended and prepended.  The other plugin collects vdi files from rsnapshot directories and measures the rsyncing from each image to the next&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;</description>
      
    </item>
    
    <item>
      <title>facebook usrbincrash php implementation</title>
      <link>http://localhost:1313/posts/facebook_usrbincrash_php_implementation/</link>
      <pubDate>Fri, 12 Feb 2010 23:25:46 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/facebook_usrbincrash_php_implementation/</guid>
      
      <description>Implementation for Facebook usr bin crash puzzle. (how/why)
I haven&#39;t touched the code for a few months, but better to put it online then to let it rot.
http://github.com/Dieterbe/facebookpuzzles/
2 branches:
master: basically what I submitted to FB, and what just works withpruning: an attempt for futher optimalisation (it only improves the runtime in some cases) but I didn&#39;t finish that version and there&#39;s a bug in it somewhere In the repo you&#39;ll also find various test input files supplied by the community on the forums and a script to benchmark the implementation on all inputfiles.</description>
      
    </item>
    
    <item>
      <title>Mysql status variables caveats</title>
      <link>http://localhost:1313/posts/mysql_status_variables_caveats/</link>
      <pubDate>Sat, 06 Jun 2009 11:33:34 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/mysql_status_variables_caveats/</guid>
      
      <description>While setting up Zenoss and reading Mysql documentation about status variables I learned:
All select_* variables (&#34;Select statistics&#34; graph in Zenoss) are actually about joins, not (all) selects. This also explains why there is no clear relation to com_select (which shows the amount of selects). (&#34;Command statistics:selects&#34; graph in Zenoss) Com_select does not denote all incoming select commands. If you have a hit on your query cache, com_select is not incremented.</description>
      
    </item>
    
    <item>
      <title>Poor mans dmenu benchmark</title>
      <link>http://localhost:1313/posts/poor_mans_dmenu_benchmark/</link>
      <pubDate>Sat, 25 Apr 2009 11:25:26 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/poor_mans_dmenu_benchmark/</guid>
      
      <description>&lt;p&gt;I wanted to know how responsive &lt;a href=&#34;http://tools.suckless.org/dmenu&#34;&gt;dmenu&lt;/a&gt; and awk, sort, uniq are on a 50MB file (625000 entries of 80 1-byte chars each).&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Tweaking Lighttpd stat() performance with fcgi-stat-accel</title>
      <link>http://localhost:1313/posts/tweaking_lighttpd_stat_performance_with_fcgi-stat-accel/</link>
      <pubDate>Mon, 03 Mar 2008 21:12:42 -0400</pubDate>
      
      <guid>http://localhost:1313/posts/tweaking_lighttpd_stat_performance_with_fcgi-stat-accel/</guid>
      
      <description>&lt;p&gt;If you serve lots of (small) files with Lighttpd you might notice you&#39;re not getting the throughput you would expect.  Other factors (such as latencies because of the random read patterns ) aside, a real show stopper is the stat() system call, which is a blocking system call ( no parallelism ).  Some clever guys thought of a way to solve this : a fastcgi program that does a stat(), so when it returns Lighty doesn&#39;t have to wait because the stat information will be in the Linux cache.  And in the meanwhile your Lighty thread can do other stuff.  
</description>
      
    </item>
    
  </channel>
</rss>
